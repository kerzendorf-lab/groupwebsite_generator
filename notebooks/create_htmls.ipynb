{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### This notebook consist of code for creating the html files for the website each time data is updated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.145701234Z",
     "start_time": "2023-11-21T07:07:35.993568325Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "from jinja2.exceptions import UndefinedError\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.276371007Z",
     "start_time": "2023-11-21T07:07:36.010519700Z"
    }
   },
   "outputs": [],
   "source": [
    "GROUP_DATA_DIR = Path(\"../../group-data\").resolve()\n",
    "MEMBERS_DIR_PATH = GROUP_DATA_DIR / \"members/\"\n",
    "WEBSITE_DATA_PATH = GROUP_DATA_DIR / \"website_data/\"\n",
    "CONTENT_DIR_PATH = WEBSITE_DATA_PATH / \"content\"\n",
    "TEMPLATE_DIR_PATH = GROUP_DATA_DIR.parent / \"groupwebsite_generator\" / \"templates\"\n",
    "HOSTING_PATH = GROUP_DATA_DIR.parent / \"kerzendorf-group.github.io\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.308005773Z",
     "start_time": "2023-11-21T07:07:36.024555660Z"
    }
   },
   "outputs": [],
   "source": [
    "# List of JSON files to be processed\n",
    "JSON_FILES_TO_LOAD = [\n",
    "    \"general\",\n",
    "    \"homepage\",\n",
    "    \"research\",\n",
    "    \"support\",\n",
    "    \"contact\",\n",
    "]\n",
    "\n",
    "# Needed columns for homepage\n",
    "ARTICLE_METADATA_FIELDS = [\n",
    "    \"article_id\",\n",
    "    \"category\",\n",
    "    \"date\",\n",
    "    \"tags\",\n",
    "    \"title\",\n",
    "    \"cover_image\",\n",
    "    \"short_description\"\n",
    "]\n",
    "# Groups and institution used in filtering data\n",
    "GROUP_FILTER = [\"DTI\", \"TARDIS\", \"ICER\", \"kerzendorf\"]\n",
    "INSTITUTION_FILTER = \"Michigan State University\"\n",
    "\n",
    "# Map roles to standardized roles for consistency\n",
    "ROLE_MAP = {\n",
    "    \"Assistant Professor\": \"Professor\",\n",
    "    \"Professor\": \"Professor\",\n",
    "    \"Visualization Consultant\": \"Visualization Consultant\",\n",
    "    \"Research Consultant\": \"Research Consultant\",\n",
    "    \"Research Software Engineer\": \"Research Software Engineer\",\n",
    "    \"Professorial Assistant\": \"Undergraduate\",\n",
    "    \"Visiting Researcher\": \"Postdoctoral Researcher\",\n",
    "    \"Postdoctoral Researcher\": \"Postdoctoral Researcher\",\n",
    "}\n",
    "\n",
    "#ROLE HIERARCHY for sorting the member list by role\n",
    "ROLE_HIERARCHY= {\n",
    "    'Professor': 1,\n",
    "    'Postdoctoral Researcher': 2,\n",
    "    'Graduate Student': 3,\n",
    "    'Undergraduate Student': 4,\n",
    "    'Undergraduate': 4,\n",
    "    'Research Consultant': 5,\n",
    "    'Research Assistant': 5,\n",
    "    'Research Software Engineer': 5,\n",
    "    'Visualization Consultant': 5\n",
    "}\n",
    "\n",
    "# Map degrees to standardized academic levels\n",
    "DEGREE_MAP = {\n",
    "    \"Masters\": \"Graduate Student\",\n",
    "    \"PhD\": \"Postdoctorate\",  #  if end_date is present\n",
    "    \"Bachelors\": \"Graduate Student\",\n",
    "}\n",
    "\n",
    "INDIVIDUAL_MEMBER_SECTION_MAP = {\n",
    "    \"education\": \"Education\",\n",
    "    \"experiences\": \"Experience\",\n",
    "    \"projects\": \"Projects\",\n",
    "    \"awards\": \"Awards & Recognition\",\n",
    "    \"outreach\": \"Outreach Programs\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Function to create proper HTML file names by replacing spaces with underscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.311056453Z",
     "start_time": "2023-11-21T07:07:36.038221785Z"
    }
   },
   "outputs": [],
   "source": [
    "def page_link(a):\n",
    "    \"\"\"Return the HTML file name after replacing blank spaces(\" \") with underscores(\"-\")\"\"\"\n",
    "    return a.replace(\" \", \"_\") if \" \" in a else a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Creating an instance of the Environment class that looks for templates. Page_link is set to the global variable so that it can be accessed by all templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.316043649Z",
     "start_time": "2023-11-21T07:07:36.043940364Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "environment = Environment(\n",
    "    loader=FileSystemLoader(TEMPLATE_DIR_PATH), extensions=[\"jinja2.ext.loopcontrols\", \"jinja2.ext.do\"]\n",
    ")\n",
    "environment.globals[\"page_link\"] = page_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for looping through JSON files and loading their content into the 'data' dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.332059602Z",
     "start_time": "2023-11-21T07:07:36.059739085Z"
    }
   },
   "outputs": [],
   "source": [
    "def loading_json_files(json_data_list):\n",
    "    \"\"\"\n",
    "    Load data from JSON files specified in a list of file names.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    json_data_list : list of str\n",
    "        A list of file names (without extension) to load as JSON.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary where keys are file names and values are the corresponding JSON data.\n",
    "\n",
    "    Raises:\n",
    "    ------\n",
    "    FileNotFoundError:\n",
    "        If a specified file does not exist.\n",
    "    json.JSONDecodeError:\n",
    "        If there's an issue decoding the JSON content from a file.\n",
    "\n",
    "    \"\"\"\n",
    "    loaded_data = {}\n",
    "    for data_id in json_data_list:\n",
    "        data_path = WEBSITE_DATA_PATH / f\"{data_id}.json\"\n",
    "\n",
    "        try:\n",
    "            with open(data_path, \"r\") as json_file:\n",
    "                loaded_data[data_id] = json.load(json_file)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File '{json_file}.json' not found.\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON in '{json_file}.json'.\")\n",
    "    return loaded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create a page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.337418487Z",
     "start_time": "2023-11-21T07:07:36.065742781Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_page(template, html, **kwargs):\n",
    "    \"\"\"\n",
    "    Create an HTML page using a Jinja2 template and save it to a specified path.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    template : str\n",
    "        The filename of the Jinja2 template to be used.\n",
    "    html : str\n",
    "        The filename of the HTML file to be generated.\n",
    "    **kwargs : dict\n",
    "        Additional keyword arguments to be passed to the Jinja2 template for rendering.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    page_template = environment.get_template(template)\n",
    "    template_level = html.count(\"/\")\n",
    "    page_html_path = HOSTING_PATH / html\n",
    "    page_content = page_template.render(TEMPLATE_LEVEL=template_level, **kwargs)\n",
    "    with open(page_html_path, mode=\"w\", encoding=\"utf-8\") as page:\n",
    "        page.write(page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataframes for articles which can be updated further "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.355136270Z",
     "start_time": "2023-11-21T07:07:36.080422459Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_content_from_files(columns):\n",
    "    \"\"\"\n",
    "    Load content data from JSON files into a Pandas DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    columns : list of str\n",
    "        A list of column names to extract from the JSON files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A DataFrame containing the specified columns from the loaded JSON files.\n",
    "\n",
    "    \"\"\"\n",
    "    content_data = {col: [] for col in columns}\n",
    "\n",
    "    for json_file in CONTENT_DIR_PATH.iterdir():\n",
    "        if json_file.suffix == \".json\":\n",
    "            with open(json_file, \"r\") as file:\n",
    "                info = json.load(file)\n",
    "                # Only load those articles where display is True\n",
    "                if info.get(\"display\"):\n",
    "                    for col in columns:\n",
    "                        content_data[col].append(info.get(col))\n",
    "\n",
    "    content_df = pd.DataFrame(content_data)\n",
    "    content_df[\"date\"] = pd.to_datetime(content_df[\"date\"], format=\"%m-%d-%Y\")\n",
    "    return content_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the Latest Content for Each Category from a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.377192621Z",
     "start_time": "2023-11-21T07:07:36.092366454Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_latest_content_df(input_data):\n",
    "    \"\"\"\n",
    "    Extract the latest content for each category from a DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : pandas.DataFrame\n",
    "        The input DataFrame containing content information.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A DataFrame containing the latest content for each category.\n",
    "\n",
    "    \"\"\"\n",
    "    # Sort the entire DataFrame by \"category\" and \"date\" in descending order\n",
    "    sorted_data = input_data.sort_values(\n",
    "        by=[\"category\", \"date\"], ascending=[True, False]\n",
    "    )\n",
    "\n",
    "    # Get the first row for each category using groupby and head\n",
    "    latest_data = sorted_data.groupby(\"category\").head(1).copy()\n",
    "    latest_data[\"date\"] = pd.to_datetime(\n",
    "        latest_data[\"date\"], format=\"%m-%d-%Y\"\n",
    "    )\n",
    "    latest_data = latest_data.sort_values(by=\"date\", ascending=False)\n",
    "\n",
    "    return latest_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing List Of JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.392640967Z",
     "start_time": "2023-11-21T07:07:36.099540795Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function Call\n",
    "data = loading_json_files(JSON_FILES_TO_LOAD)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homepage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing selected columns for Homepage only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.437636192Z",
     "start_time": "2023-11-21T07:07:36.114973108Z"
    }
   },
   "outputs": [],
   "source": [
    "content_df = load_content_from_files(ARTICLE_METADATA_FIELDS)\n",
    "latest_content_df = get_latest_content_df(content_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.460321141Z",
     "start_time": "2023-11-21T07:07:36.164866903Z"
    }
   },
   "outputs": [],
   "source": [
    "create_page(\n",
    "    \"homepage.html.j2\",\n",
    "    \"index.html\",\n",
    "    general=data[\"general\"],\n",
    "    homepage=data[\"homepage\"],\n",
    "    recent_content=latest_content_df.to_dict(orient=\"records\"),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### People Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering based on group and institution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.460567962Z",
     "start_time": "2023-11-21T07:07:36.165051029Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def filter_edu_exp_data(df, valid_groups,valid_institution):\n",
    "    \"\"\"\n",
    "    Filter education and experience data based on specified criteria.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing education and experience data.\n",
    "    valid_groups : list\n",
    "        List of valid groups to include in the filtered data.\n",
    "    valid_institution : str\n",
    "        The valid institution to include in the filtered data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A filtered DataFrame containing only the rows that meet the specified criteria.\n",
    "    \"\"\"\n",
    "    group_mask = False\n",
    "    institution_mask = False\n",
    "\n",
    "    # Check if 'group' column exists and update mask accordingly\n",
    "    if \"group\" in df.columns:\n",
    "        group_mask = df[\"group\"].isin(valid_groups)\n",
    "\n",
    "    # Check if 'institution' column exists and update mask accordingly\n",
    "    if \"institution\" in df.columns:\n",
    "        institution_mask = df[\"institution\"] == valid_institution\n",
    "\n",
    "    final_mask = group_mask | institution_mask\n",
    "    return df[final_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to load education data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.460643612Z",
     "start_time": "2023-11-21T07:07:36.209021018Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_education_experience_data(directory):\n",
    "    \"\"\"\n",
    "    Load education and experience data from JSON files, filter based on criteria, and perform preprocessing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    directory : str or pathlib.Path\n",
    "        The directory path containing \"experiences.json\" and \"education.json\" files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A DataFrame containing filtered and preprocessed education and experience data.\n",
    "    \"\"\"\n",
    "    filtered_records = []\n",
    "    file_names = [\"experiences.json\", \"education.json\"]\n",
    "    for file_name in file_names:\n",
    "        file_path = directory / file_name\n",
    "        if file_path.exists():\n",
    "            # Reading JSON data directly into a DataFrame\n",
    "            records = pd.read_json(file_path)\n",
    "\n",
    "            # filtering based on group and institution\n",
    "            valid_records = filter_edu_exp_data(records, GROUP_FILTER, INSTITUTION_FILTER)\n",
    "\n",
    "            filtered_records.append(valid_records)\n",
    "        else:\n",
    "            print(f\"{file_path} does not exist\")\n",
    "\n",
    "    if filtered_records:\n",
    "        combined_records = pd.concat(filtered_records, ignore_index=True)\n",
    "    else:\n",
    "        combined_records = pd.DataFrame()\n",
    "\n",
    "    # if start_date column exists, fill with NaN if it doesn't\n",
    "    if \"start_date\" not in combined_records:\n",
    "        combined_records[\"start_date\"] = pd.NaT\n",
    "\n",
    "    # Convert start_date to datetime format\n",
    "    combined_records[\"start_date\"] = pd.to_datetime(combined_records[\"start_date\"], errors=\"coerce\")\n",
    "\n",
    "    # Sort the DataFrame based on start_date\n",
    "    combined_records = combined_records.sort_values(by=\"start_date\", ascending=False)\n",
    "    return combined_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function load social links directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.460739282Z",
     "start_time": "2023-11-21T07:07:36.209176046Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_social_links(social_dir):\n",
    "    \"\"\"\n",
    "    Load social links from a JSON file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    social_dir : str or pathlib.Path\n",
    "        The directory path containing the \"social_links.json\" file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict or None\n",
    "        A dictionary containing social links or None if the file doesn't exist.\n",
    "    \"\"\"\n",
    "    social_links = None\n",
    "    social_links_file_path = social_dir / \"social_links.json\"\n",
    "    if social_links_file_path.exists():\n",
    "        with open(social_links_file_path, \"r\") as f:\n",
    "            social_links = json.load(f)\n",
    "    return social_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to load topmost project title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.460804351Z",
     "start_time": "2023-11-21T07:07:36.209270143Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_latest_project_title(project_dir):\n",
    "    \"\"\"\n",
    "    Load the title of the topmost project from a JSON file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    project_dir : str or pathlib.Path\n",
    "        The directory path containing the \"projects.json\" file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str or None\n",
    "        The title of the topmost project or None if the file doesn't exist or is empty.\n",
    "    \"\"\"\n",
    "    projects_file_path = project_dir / \"projects.json\"\n",
    "    topmost_project_title = None\n",
    "    if projects_file_path.exists():\n",
    "        projects_df = pd.read_json(projects_file_path)\n",
    "        if not projects_df.empty:\n",
    "            # Fetching the project title from the first row of the DataFrame\n",
    "            topmost_project_title = projects_df.iloc[0].get(\"project_title\")\n",
    "    return topmost_project_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funtion to parse member data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.460863639Z",
     "start_time": "2023-11-21T07:07:36.209362246Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def parse_member_data(member_dir):\n",
    "    \"\"\"\n",
    "    Parse member-related data from JSON files in the specified directory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    member_dir : str or pathlib.Path\n",
    "        The directory path containing member-related JSON files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        A tuple containing education and experience DataFrame, social links dictionary,\n",
    "        and the title of the current project.\n",
    "    \"\"\"\n",
    "    member_json_dir = member_dir / \"jsons\"\n",
    "    education_experience_df = load_education_experience_data(member_json_dir)\n",
    "    current_project_title = load_latest_project_title(member_json_dir)\n",
    "    social_links = load_social_links(member_json_dir)\n",
    "\n",
    "    return education_experience_df, social_links, current_project_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.460921063Z",
     "start_time": "2023-11-21T07:07:36.209452896Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to extract academic roles from education and experience data\n",
    "def extract_member_academic_role(education_experience_df):\n",
    "    \"\"\"\n",
    "    Extract the current academic role of a member based on education and experience data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    education_experience_df : pandas.DataFrame\n",
    "        DataFrame containing education and experience data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[str, bool]\n",
    "        A tuple containing:\n",
    "        - str: The current academic role of the member.\n",
    "        - bool: True if the member is currently active, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if these columns exist in dataframe\n",
    "    for column in [\"end_date\", \"group\", \"institution\"]:\n",
    "        if column not in education_experience_df.columns:\n",
    "            education_experience_df[column] = None\n",
    "\n",
    "    current_academic_role = None\n",
    "\n",
    "    for _, row in education_experience_df.iterrows():\n",
    "        role = row.get(\"role\", None)\n",
    "        degree = row.get(\"degree\", None)\n",
    "\n",
    "        if not current_academic_role:\n",
    "            current_academic_role = ROLE_MAP.get(role, \"\")\n",
    "\n",
    "            if degree == \"PhD\" and pd.isna(row[\"end_date\"]):\n",
    "                current_academic_role = \"Graduate Student\"  # if end_date is NaN\n",
    "            elif degree == \"Bachelors\" and pd.isna(row[\"end_date\"]):\n",
    "                current_academic_role = \"Undergraduate Student\"\n",
    "            elif not current_academic_role and degree in DEGREE_MAP:\n",
    "                current_academic_role = DEGREE_MAP[degree]\n",
    "\n",
    "    # Check for end dates outside the loop\n",
    "    has_end_date = all(\n",
    "        not pd.isna(date) for date in education_experience_df[\"end_date\"]\n",
    "    )\n",
    "    is_current_member = not has_end_date\n",
    "\n",
    "    return current_academic_role, is_current_member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def custom_role_sort(roles):\n",
    "    \"\"\"\n",
    "    Sorts a list of roles based on academic role hierarchy and then by name.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    roles : list[dict]\n",
    "        List of dictionaries representing roles. Each dictionary should contain at least the keys 'academic_role' and 'name'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[dict]\n",
    "        A sorted list of roles based on the academic role hierarchy and, in case of ties, sorted by name in ascending order.\n",
    "    \"\"\"\n",
    "    sorted_roles = sorted(roles, key=lambda x: (ROLE_HIERARCHY.get(x['academic_role'], float('inf')), x['name']))\n",
    "    return sorted_roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.460978768Z",
     "start_time": "2023-11-21T07:07:36.209625649Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lists to store data for current and alumni members\n",
    "def fetch_member_data():\n",
    "    \"\"\"\n",
    "    Fetch and process member data from directories in the specified members' directory.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[list, list]\n",
    "        A tuple containing two lists:\n",
    "        1. List of dictionaries representing current members' data.\n",
    "        2. List of dictionaries representing alumni members' data.\n",
    "\n",
    "    \"\"\"\n",
    "    current_people_page_list = []\n",
    "    alumni_people_page_list = []\n",
    "    # Looping through member directories to fetch and process member data\n",
    "    for member_dir in MEMBERS_DIR_PATH.glob(\"*\"):\n",
    "        if not (member_info_fname := member_dir / \"info.json\").exists():\n",
    "            continue\n",
    "        with open(member_info_fname, \"r\") as file:\n",
    "            member_info = json.load(file)\n",
    "        (\n",
    "            education_experience_df,\n",
    "            social_links,\n",
    "            current_project_title,\n",
    "        ) = parse_member_data(member_dir)\n",
    "        current_academic_role, is_current_member = extract_member_academic_role(\n",
    "            education_experience_df\n",
    "        )\n",
    "        first_name = member_info[\"first_name\"]\n",
    "        last_name = member_info[\"last_name\"]\n",
    "        nick_name = member_info.get(\"nick_name\")\n",
    "        member_id = member_info[\"id\"]\n",
    "        image_path = member_info[\"image_path\"]\n",
    "        cover_image_path = member_info[\"cover_image_path\"]\n",
    "\n",
    "        name = f\"{nick_name if nick_name else first_name} {last_name}\"\n",
    "        member_data = {\n",
    "            \"name\": name,\n",
    "            \"academic_role\": current_academic_role,\n",
    "            \"id\": member_id,\n",
    "            \"current_project_title\": current_project_title,\n",
    "            \"image_path\": image_path,\n",
    "            \"cover_image_path\": cover_image_path,\n",
    "        }\n",
    "\n",
    "        if social_links is not None:\n",
    "            member_data[\"social_links\"] = social_links\n",
    "            \n",
    "        if is_current_member:\n",
    "            current_people_page_list.append(member_data)\n",
    "        else:\n",
    "            alumni_people_page_list.append(member_data)\n",
    "\n",
    "    # # Sort current members by role\n",
    "    current_people_page_list = custom_role_sort(current_people_page_list)\n",
    "    \n",
    "    # # Sort alumni members by role\n",
    "    alumni_people_page_list = custom_role_sort(alumni_people_page_list)\n",
    "    return current_people_page_list, alumni_people_page_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.566682059Z",
     "start_time": "2023-11-21T07:07:36.209725227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/abhinav/workspace/code/tardis-main/kerzendorf-group/group-data/members/jack_o_brien/jsons/experiences.json does not exist\n",
      "/home/abhinav/workspace/code/tardis-main/kerzendorf-group/group-data/members/hayden_monk/jsons/experiences.json does not exist\n",
      "/home/abhinav/workspace/code/tardis-main/kerzendorf-group/group-data/members/vicente_amado/jsons/experiences.json does not exist\n",
      "/home/abhinav/workspace/code/tardis-main/kerzendorf-group/group-data/members/yuki_matsumura/jsons/experiences.json does not exist\n",
      "/home/abhinav/workspace/code/tardis-main/kerzendorf-group/group-data/members/sona_chitchyan/jsons/education.json does not exist\n",
      "/home/abhinav/workspace/code/tardis-main/kerzendorf-group/group-data/members/alexander_grunewald/jsons/experiences.json does not exist\n"
     ]
    }
   ],
   "source": [
    "current_people_page_list, alumni_people_page_list = fetch_member_data()\n",
    "all_people_page_list = current_people_page_list + alumni_people_page_list\n",
    "all_people_data = {person[\"id\"]: person for person in all_people_page_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.568783353Z",
     "start_time": "2023-11-21T07:07:36.414645144Z"
    }
   },
   "outputs": [],
   "source": [
    "create_page(\n",
    "    \"people.html.j2\",\n",
    "    \"People.html\",\n",
    "    general=data[\"general\"],\n",
    "    current_members=current_people_page_list,\n",
    "    alumni_members=alumni_people_page_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current Members Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_page(\n",
    "    \"current_members.html.j2\",\n",
    "    \"current_members.html\",\n",
    "    general=data[\"general\"],\n",
    "    current_members=current_people_page_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alumni Members Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_page(\n",
    "    \"alumni_members.html.j2\",\n",
    "    \"alumni_members.html\",\n",
    "    general=data[\"general\"],\n",
    "    alumni_members=alumni_people_page_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions to extract data about an individual member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def try_load_json_file(file_path):\n",
    "    \"\"\"\n",
    "    Attempt to load JSON data from a file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        The path to the JSON file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict or None\n",
    "        Returns a dictionary containing the parsed JSON data if successful,\n",
    "        otherwise returns None if an error occurs or the file is inaccessible.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            return json.load(file)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def load_individual_member_data(member_id):\n",
    "    \"\"\"\n",
    "    Load data for an individual member based on their unique ID.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    member_id : str\n",
    "        Unique identifier for the member.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        A tuple containing:\n",
    "        - dict: Basic information about the member loaded from 'info.json'.\n",
    "        - dict: Dictionary containing various categories of member data loaded from respective JSON files.\n",
    "            The keys correspond to categories mapped in INDIVIDUAL_MEMBER_SECTION_MAP,\n",
    "            and values are dictionaries containing data for each category.\n",
    "    \"\"\"\n",
    "    member_dir = MEMBERS_DIR_PATH / member_id\n",
    "    member_jsons_dir = member_dir / \"jsons\"\n",
    "\n",
    "    basic_info = try_load_json_file(member_dir / \"info.json\")\n",
    "\n",
    "    member_all_data = {}\n",
    "    for category in INDIVIDUAL_MEMBER_SECTION_MAP:\n",
    "        member_all_data[category] = try_load_json_file(member_jsons_dir / f\"{category}.json\")\n",
    "    \n",
    "    return basic_info, member_all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "columns = [\"people_involved_ids\", \"category\", \"date\", \"title\", \"article_id\"]\n",
    "content_df = load_content_from_files(columns)\n",
    "\n",
    "for person_id, person_data in all_people_data.items():\n",
    "    basic_info, member_all_data = load_individual_member_data(person_id)\n",
    "    create_page(\n",
    "        \"individual_person.html.j2\",\n",
    "        f\"members/{person_id}/{person_id}.html\",\n",
    "        general=data[\"general\"],\n",
    "        member_id=person_id,\n",
    "        member_data=person_data,\n",
    "        basic_info=basic_info,\n",
    "        category_data=member_all_data,\n",
    "        section_headings=INDIVIDUAL_MEMBER_SECTION_MAP,\n",
    "        content=content_df.to_dict(orient='records')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Contact Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.569018310Z",
     "start_time": "2023-11-21T07:07:36.457030906Z"
    }
   },
   "outputs": [],
   "source": [
    "create_page(\n",
    "    \"contact.html.j2\",\n",
    "    \"Contact.html\",\n",
    "    general=data[\"general\"],\n",
    "    contact=data[\"contact\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Support Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.588932886Z",
     "start_time": "2023-11-21T07:07:36.457249500Z"
    }
   },
   "outputs": [],
   "source": [
    "create_page(\n",
    "    \"support.html.j2\",\n",
    "    \"Support.html\",\n",
    "    general=data[\"general\"],\n",
    "    support=data[\"support\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Research Front Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For adding more columns in dataframe to render front pages and individual article pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.589164156Z",
     "start_time": "2023-11-21T07:07:36.500941056Z"
    }
   },
   "outputs": [],
   "source": [
    "columns_extended = ARTICLE_METADATA_FIELDS + [\"author_id\"]\n",
    "content_df = load_content_from_files(columns_extended)\n",
    "research_content_df = content_df[content_df[\"category\"] != \"News\"].sort_values(\n",
    "    by=[\"category\", \"date\"], ascending=[True, False]\n",
    ")\n",
    "latest_content_df = get_latest_content_df(content_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>cover_image</th>\n",
       "      <th>short_description</th>\n",
       "      <th>author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>snr0509_josh_paper</td>\n",
       "      <td>Astrophysical Transients</td>\n",
       "      <td>2023-05-28</td>\n",
       "      <td>[research, news]</td>\n",
       "      <td>A comprehensive SN Ia companion search in SNR ...</td>\n",
       "      <td>website_files/images/article_content/snr0509_v...</td>\n",
       "      <td>A search for a surviving companion to a 400 ye...</td>\n",
       "      <td>josh_shields</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sn1006_josh_paper</td>\n",
       "      <td>Astrophysical Transients</td>\n",
       "      <td>2022-07-10</td>\n",
       "      <td>[research, news]</td>\n",
       "      <td>Searching for a Hypervelocity White Dwarf SN I...</td>\n",
       "      <td>website_files/images/article_content/sn1006_vi...</td>\n",
       "      <td>Testing a promising SN Ia progenitor channel b...</td>\n",
       "      <td>josh_shields</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>midsure22_poster_bea</td>\n",
       "      <td>Computational Metascience</td>\n",
       "      <td>2022-07-22</td>\n",
       "      <td>[research]</td>\n",
       "      <td>MIDSURE 2022</td>\n",
       "      <td>website_files/images/article_content/bea_midsu...</td>\n",
       "      <td>Poster presentation at the Mid-Michigan Sympos...</td>\n",
       "      <td>bea_lu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uuraf21_poster_vicente</td>\n",
       "      <td>Computational Metascience</td>\n",
       "      <td>2021-04-19</td>\n",
       "      <td>[research]</td>\n",
       "      <td>MSU UURAF 2021</td>\n",
       "      <td>website_files/images/article_content/MAST_Post...</td>\n",
       "      <td>Poster presentation for MSU's University Under...</td>\n",
       "      <td>vicente_amado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               article_id                   category       date  \\\n",
       "3      snr0509_josh_paper   Astrophysical Transients 2023-05-28   \n",
       "0       sn1006_josh_paper   Astrophysical Transients 2022-07-10   \n",
       "4    midsure22_poster_bea  Computational Metascience 2022-07-22   \n",
       "2  uuraf21_poster_vicente  Computational Metascience 2021-04-19   \n",
       "\n",
       "               tags                                              title  \\\n",
       "3  [research, news]  A comprehensive SN Ia companion search in SNR ...   \n",
       "0  [research, news]  Searching for a Hypervelocity White Dwarf SN I...   \n",
       "4        [research]                                       MIDSURE 2022   \n",
       "2        [research]                                     MSU UURAF 2021   \n",
       "\n",
       "                                         cover_image  \\\n",
       "3  website_files/images/article_content/snr0509_v...   \n",
       "0  website_files/images/article_content/sn1006_vi...   \n",
       "4  website_files/images/article_content/bea_midsu...   \n",
       "2  website_files/images/article_content/MAST_Post...   \n",
       "\n",
       "                                   short_description      author_id  \n",
       "3  A search for a surviving companion to a 400 ye...   josh_shields  \n",
       "0  Testing a promising SN Ia progenitor channel b...   josh_shields  \n",
       "4  Poster presentation at the Mid-Michigan Sympos...         bea_lu  \n",
       "2  Poster presentation for MSU's University Under...  vicente_amado  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_content_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.589247191Z",
     "start_time": "2023-11-21T07:07:36.501093779Z"
    }
   },
   "outputs": [],
   "source": [
    "create_page(\n",
    "    \"research.html.j2\",\n",
    "    \"Research.html\",\n",
    "    general=data[\"general\"],\n",
    "    content=research_content_df,\n",
    "    research=data[\"research\"],\n",
    "    current_members=current_people_page_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.589414282Z",
     "start_time": "2023-11-21T07:07:36.544920583Z"
    }
   },
   "outputs": [],
   "source": [
    "folder_path = Path(HOSTING_PATH) / \"sub_research\"\n",
    "folder_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for category in content_df.loc[content_df.category != \"News\", \"category\"].unique():\n",
    "    create_page(\n",
    "        \"sub_research_frontpage.html.j2\",\n",
    "        f\"sub_research/{page_link(category.lower())}.html\",\n",
    "        general=data[\"general\"],\n",
    "        research=data[\"research\"],\n",
    "        content=research_content_df,\n",
    "        category=category,\n",
    "        current_members=current_people_page_list\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.589414282Z",
     "start_time": "2023-11-21T07:07:36.544920583Z"
    }
   },
   "source": [
    "Individual Research Page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.589414282Z",
     "start_time": "2023-11-21T07:07:36.544920583Z"
    }
   },
   "outputs": [],
   "source": [
    "columns_extended = ARTICLE_METADATA_FIELDS + [\"author_id\", \"people_involved_ids\", \"links\", \"content\", \"long_description\"]\n",
    "content_df = load_content_from_files(columns_extended)\n",
    "ind_research_content_df = content_df[content_df[\"category\"] != \"News\"].sort_values(\n",
    "    by=[\"category\", \"date\"], ascending=[True, False]\n",
    ")\n",
    "\n",
    "\n",
    "for ind_research_keys, ind_research_values in ind_research_content_df.iterrows():\n",
    "    \n",
    "    folder_path = Path(HOSTING_PATH) / \"sub_research\" / page_link(ind_research_values.category.lower())\n",
    "    folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    create_page(\n",
    "        \"research_page_no_twitter.html.j2\",\n",
    "        f\"sub_research/{page_link(ind_research_values.category.lower())}/{page_link(ind_research_values.article_id.lower())}.html\",\n",
    "        general=data[\"general\"],\n",
    "        content=ind_research_values,\n",
    "        member_data=all_people_data,\n",
    "        article_id=ind_research_values['article_id']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### News Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:10:29.508008736Z",
     "start_time": "2023-11-21T07:10:29.418263240Z"
    }
   },
   "outputs": [],
   "source": [
    "columns_extended = ARTICLE_METADATA_FIELDS + [\"author_id\", \"people_involved_ids\", \"content\", \"long_description\"]\n",
    "content_df = load_content_from_files(columns_extended)\n",
    "\n",
    "news_content_df = content_df[\n",
    "    (content_df[\"category\"] == \"News\") | (content_df[\"tags\"].apply(lambda x: \"news\" in x if isinstance(x, list) else False))\n",
    "].sort_values(by=[\"date\"], ascending=[False])\n",
    "\n",
    "create_page(\n",
    "    \"news.html.j2\",\n",
    "    \"News.html\",\n",
    "    general=data[\"general\"],\n",
    "    research=data[\"research\"],\n",
    "    content=news_content_df,\n",
    "    member_data=all_people_data,\n",
    "    category=\"News\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual News Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_news_keys, ind_news_values in news_content_df.iterrows():\n",
    "\n",
    "    folder_path = Path(HOSTING_PATH) / \"news\" / page_link(ind_news_values.article_id.lower())\n",
    "    folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    create_page(\n",
    "        \"news_page_no_twitter.html.j2\",\n",
    "        f\"news/{page_link(ind_news_values.article_id.lower())}.html\",\n",
    "        general=data[\"general\"],\n",
    "        content=ind_news_values,\n",
    "        member_data=all_people_data,\n",
    "        category=\"News\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
