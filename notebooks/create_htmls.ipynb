{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### This notebook consist of code for creating the html files for the website each time data is updated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "from jinja2.exceptions import UndefinedError\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_DATA_DIR = Path(\"../..//group-data\")\n",
    "MEMBERS_DIR_PATH = GROUP_DATA_DIR / \"members/\"\n",
    "WEBSITE_DATA_PATH = GROUP_DATA_DIR / \"website_data/\"\n",
    "CONTENT_DIR_PATH = WEBSITE_DATA_PATH / \"content\"\n",
    "TEMPLATE_DIR_PATH = GROUP_DATA_DIR.parent / \"groupwebsite_generator\" / \"templates\"\n",
    "HOSTING_PATH = GROUP_DATA_DIR.parent / \"kerzendorf-group.github.io\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of JSON files to be processed\n",
    "JSON_FILES_TO_LOAD = [\n",
    "    \"general\",\n",
    "    \"homepage\",\n",
    "    \"research\",\n",
    "    \"support\",\n",
    "    \"contact\",\n",
    "]\n",
    "# Needed columns for homepage\n",
    "ARTICLE_METADATA_FIELDS = [\n",
    "    \"article_id\",\n",
    "    \"category\",\n",
    "    \"date\",\n",
    "    \"tags\",\n",
    "    \"title\",\n",
    "    \"cover_image\",\n",
    "    \"short_description\",\n",
    "]\n",
    "# Groups and institution used in filtering data\n",
    "GROUP_FILTER = [\"DTI\", \"TARDIS\", \"ICER\", \"kerzendorf\"]\n",
    "INSTITUTION_FILTER = \"Michigan State University\"\n",
    "\n",
    "# Map roles to standardized roles for consistency\n",
    "ROLE_MAP = {\n",
    "    \"Assistant Professor\": \"Professor\",\n",
    "    \"Professor\": \"Professor\",\n",
    "    \"Visualization Consultant\": \"Visualization Consultant\",\n",
    "    \"Research Consultant\": \"Research Consultant\",\n",
    "    \"Research Software Engineer\": \"Research Software Engineer\",\n",
    "    \"Professorial Assistant\": \"Undergraduate\",\n",
    "    \"Visiting Researcher\": \"Postdoctoral Researcher\",\n",
    "    \"Postdoctoral Researcher\": \"Postdoctoral Researcher\",\n",
    "}\n",
    "\n",
    "# Map degrees to standardized academic levels\n",
    "DEGREE_MAP = {\n",
    "    \"Masters\": \"Graduate Student\",\n",
    "    \"PhD\": \"Postdoctorate\",  #  if end_date is present\n",
    "    \"Bachelors\": \"Graduate Student\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Function to create proper HTML file names by replacing spaces with underscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def page_link(a):\n",
    "    \"\"\"Return the HTML file name after replacing blank spaces(\" \") with underscores(\"-\")\"\"\"\n",
    "    return a.replace(\" \", \"_\") if \" \" in a else a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Creating an instance of the Environment class that looks for templates. Page_link is set to the global variable so that it can be accessed by all templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "environment = Environment(\n",
    "    loader=FileSystemLoader(TEMPLATE_DIR_PATH), extensions=[\"jinja2.ext.loopcontrols\"]\n",
    ")\n",
    "environment.globals[\"page_link\"] = page_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for looping through JSON files and loading their content into the 'data' dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_json_files(json_data_list):\n",
    "    \"\"\"\n",
    "    Load data from JSON files specified in a list of file names.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    json_data_list : list of str\n",
    "        A list of file names (without extension) to load as JSON.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary where keys are file names and values are the corresponding JSON data.\n",
    "\n",
    "    Raises:\n",
    "    ------\n",
    "    FileNotFoundError:\n",
    "        If a specified file does not exist.\n",
    "    json.JSONDecodeError:\n",
    "        If there's an issue decoding the JSON content from a file.\n",
    "\n",
    "    \"\"\"\n",
    "    loaded_data = {}\n",
    "    for data_id in json_data_list:\n",
    "        data_path = WEBSITE_DATA_PATH / f\"{data_id}.json\"\n",
    "\n",
    "        try:\n",
    "            with open(data_path, \"r\") as json_file:\n",
    "                loaded_data[data_id] = json.load(json_file)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File '{json_file}.json' not found.\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON in '{json_file}.json'.\")\n",
    "    return loaded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create a page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_page(template, html, **kwargs):\n",
    "    \"\"\"\n",
    "    Create an HTML page using a Jinja2 template and save it to a specified path.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    template : str\n",
    "        The filename of the Jinja2 template to be used.\n",
    "    html : str\n",
    "        The filename of the HTML file to be generated.\n",
    "    **kwargs : dict\n",
    "        Additional keyword arguments to be passed to the Jinja2 template for rendering.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    page_template = environment.get_template(template)\n",
    "    page_html_path = HOSTING_PATH / html\n",
    "    page_content = page_template.render(**kwargs)\n",
    "    with open(page_html_path, mode=\"w\", encoding=\"utf-8\") as page:\n",
    "        page.write(page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataframes for articles which can be updated further "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_content_from_files(columns):\n",
    "    \"\"\"\n",
    "    Load content data from JSON files into a Pandas DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    columns : list of str\n",
    "        A list of column names to extract from the JSON files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A DataFrame containing the specified columns from the loaded JSON files.\n",
    "\n",
    "    \"\"\"\n",
    "    content_data = {col: [] for col in columns}\n",
    "\n",
    "    for json_file in os.listdir(CONTENT_DIR_PATH):\n",
    "        if json_file.endswith(\".json\"):\n",
    "            json_path = os.path.join(CONTENT_DIR_PATH, json_file)\n",
    "            with open(json_path, \"r\") as file:\n",
    "                info = json.load(file)\n",
    "                # Only load those articles where display is True\n",
    "                if info.get(\"display\"):\n",
    "                    for col in columns:\n",
    "                        content_data[col].append(info.get(col))\n",
    "\n",
    "    content_df = pd.DataFrame(content_data)\n",
    "    content_df[\"date\"] = pd.to_datetime(content_df[\"date\"], format=\"%m-%d-%Y\")\n",
    "    return content_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the Latest Content for Each Category from a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_latest_content_df(input_data):\n",
    "    \"\"\"\n",
    "    Extract the latest content for each category from a DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : pandas.DataFrame\n",
    "        The input DataFrame containing content information.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A DataFrame containing the latest content for each category.\n",
    "\n",
    "    \"\"\"\n",
    "    # Sort the entire DataFrame by \"category\" and \"date\" in descending order\n",
    "    sorted_data = input_data.sort_values(\n",
    "        by=[\"category\", \"date\"], ascending=[True, False]\n",
    "    )\n",
    "\n",
    "    # Get the first row for each category using groupby and head\n",
    "    latest_data = sorted_data.groupby(\"category\").head(1).copy()\n",
    "    latest_data[\"date\"] = pd.to_datetime(\n",
    "        latest_data[\"date\"], format=\"%m-%d-%Y\"\n",
    "    )\n",
    "    latest_data = latest_data.sort_values(by=\"date\", ascending=False)\n",
    "\n",
    "    return latest_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing List Of JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Call\n",
    "data = loading_json_files(JSON_FILES_TO_LOAD)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homepage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing selected columns for Homepage only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_df = load_content_from_files(ARTICLE_METADATA_FIELDS)\n",
    "latest_content_df = get_latest_content_df(content_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_page(\n",
    "    \"homepage.html.j2\",\n",
    "    \"Index.html\",\n",
    "    general=data[\"general\"],\n",
    "    homepage=data[\"homepage\"],\n",
    "    recent_content=latest_content_df.to_dict(orient=\"records\"),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### People Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering based on group and institution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_edu_exp_data(df, valid_groups,valid_institution):\n",
    "    \"\"\"\n",
    "    Filter education and experience data based on specified criteria.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing education and experience data.\n",
    "    valid_groups : list\n",
    "        List of valid groups to include in the filtered data.\n",
    "    valid_institution : str\n",
    "        The valid institution to include in the filtered data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A filtered DataFrame containing only the rows that meet the specified criteria.\n",
    "    \"\"\"\n",
    "    group_mask = False\n",
    "    institution_mask = False\n",
    "\n",
    "    # Check if 'group' column exists and update mask accordingly\n",
    "    if \"group\" in df.columns:\n",
    "        group_mask = df[\"group\"].isin(valid_groups)\n",
    "\n",
    "    # Check if 'institution' column exists and update mask accordingly\n",
    "    if \"institution\" in df.columns:\n",
    "        institution_mask = df[\"institution\"] == valid_institution\n",
    "\n",
    "    final_mask = group_mask | institution_mask\n",
    "    return df[final_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to load education data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_education_experience_data(directory):\n",
    "    \"\"\"\n",
    "    Load education and experience data from JSON files, filter based on criteria, and perform preprocessing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    directory : str or pathlib.Path\n",
    "        The directory path containing \"experiences.json\" and \"education.json\" files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A DataFrame containing filtered and preprocessed education and experience data.\n",
    "    \"\"\"\n",
    "    filtered_records = []\n",
    "    file_names = [\"experiences.json\", \"education.json\"]\n",
    "    for file_name in file_names:\n",
    "        file_path = directory / file_name\n",
    "        if file_path.exists():\n",
    "            # Reading JSON data directly into a DataFrame\n",
    "            records = pd.read_json(file_path)\n",
    "\n",
    "            # filtering based on group and institution\n",
    "            valid_records = filter_edu_exp_data(records, GROUP_FILTER, INSTITUTION_FILTER)\n",
    "\n",
    "            filtered_records.append(valid_records)\n",
    "        else:\n",
    "            print(f\"{file_path} does not exist\")\n",
    "\n",
    "    if filtered_records:\n",
    "        combined_records = pd.concat(filtered_records, ignore_index=True)\n",
    "    else:\n",
    "        combined_records = pd.DataFrame()\n",
    "\n",
    "    # if start_date column exists, fill with NaN if it doesn't\n",
    "    if \"start_date\" not in combined_records:\n",
    "        combined_records[\"start_date\"] = pd.NaT\n",
    "\n",
    "    # Convert start_date to datetime format\n",
    "    combined_records[\"start_date\"] = pd.to_datetime(combined_records[\"start_date\"], errors=\"coerce\")\n",
    "\n",
    "    # Sort the DataFrame based on start_date\n",
    "    combined_records = combined_records.sort_values(by=\"start_date\", ascending=False)\n",
    "    return combined_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function load social links directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_social_links(social_dir):\n",
    "    \"\"\"\n",
    "    Load social links from a JSON file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    social_dir : str or pathlib.Path\n",
    "        The directory path containing the \"social_links.json\" file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict or None\n",
    "        A dictionary containing social links or None if the file doesn't exist.\n",
    "    \"\"\"\n",
    "    social_links = None\n",
    "    social_links_file_path = social_dir / \"social_links.json\"\n",
    "    if social_links_file_path.exists():\n",
    "        with open(social_links_file_path, \"r\") as f:\n",
    "            social_links = json.load(f)\n",
    "    return social_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to load topmost project title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_latest_project_title(project_dir):\n",
    "    \"\"\"\n",
    "    Load the title of the topmost project from a JSON file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    project_dir : str or pathlib.Path\n",
    "        The directory path containing the \"projects.json\" file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str or None\n",
    "        The title of the topmost project or None if the file doesn't exist or is empty.\n",
    "    \"\"\"\n",
    "    projects_file_path = project_dir / \"projects.json\"\n",
    "    topmost_project_title = None\n",
    "    if projects_file_path.exists():\n",
    "        projects_df = pd.read_json(projects_file_path)\n",
    "        if not projects_df.empty:\n",
    "            # Fetching the project title from the first row of the DataFrame\n",
    "            topmost_project_title = projects_df.iloc[0].get(\"project_title\")\n",
    "    return topmost_project_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funtion to parse member data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def parse_member_data(member_dir):\n",
    "    \"\"\"\n",
    "    Parse member-related data from JSON files in the specified directory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    member_dir : str or pathlib.Path\n",
    "        The directory path containing member-related JSON files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        A tuple containing education and experience DataFrame, social links dictionary,\n",
    "        and the title of the current project.\n",
    "    \"\"\"\n",
    "    member_json_dir = member_dir / \"jsons\"\n",
    "    education_experience_df = load_education_experience_data(member_json_dir)\n",
    "    current_project_title = load_latest_project_title(member_json_dir)\n",
    "    social_links = load_social_links(member_json_dir)\n",
    "\n",
    "    return education_experience_df, social_links, current_project_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract academic roles from education and experience data\n",
    "def extract_member_academic_role(education_experience_df):\n",
    "    \"\"\"\n",
    "    Extract the current academic role of a member based on education and experience data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    education_experience_df : pandas.DataFrame\n",
    "        DataFrame containing education and experience data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[str, bool]\n",
    "        A tuple containing:\n",
    "        - str: The current academic role of the member.\n",
    "        - bool: True if the member is currently active, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if these columns exist in dataframe\n",
    "    for column in [\"end_date\", \"group\", \"institution\"]:\n",
    "        if column not in education_experience_df.columns:\n",
    "            education_experience_df[column] = None\n",
    "\n",
    "    current_academic_role = None\n",
    "\n",
    "    for _, row in education_experience_df.iterrows():\n",
    "        role = row.get(\"role\", None)\n",
    "        degree = row.get(\"degree\", None)\n",
    "\n",
    "        if not current_academic_role:\n",
    "            current_academic_role = ROLE_MAP.get(role, \"\")\n",
    "\n",
    "            if degree == \"PhD\" and pd.isna(row[\"end_date\"]):\n",
    "                current_academic_role = \"Graduate Student\"  # if end_date is NaN\n",
    "            elif degree == \"Bachelors\" and pd.isna(row[\"end_date\"]):\n",
    "                current_academic_role = \"Undergraduate Student\"\n",
    "            elif not current_academic_role and degree in DEGREE_MAP:\n",
    "                current_academic_role = DEGREE_MAP[degree]\n",
    "\n",
    "    # Check for end dates outside the loop\n",
    "    has_end_date = all(\n",
    "        not pd.isna(date) for date in education_experience_df[\"end_date\"]\n",
    "    )\n",
    "    is_current_member = not has_end_date\n",
    "\n",
    "    return current_academic_role, is_current_member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lists to store data for current and alumni members\n",
    "def fetch_member_data():\n",
    "    \"\"\"\n",
    "    Fetch and process member data from directories in the specified members' directory.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[list, list]\n",
    "        A tuple containing two lists:\n",
    "        1. List of dictionaries representing current members' data.\n",
    "        2. List of dictionaries representing alumni members' data.\n",
    "\n",
    "    \"\"\"\n",
    "    current_people_page_list = []\n",
    "    alumni_people_page_list = []\n",
    "    # Looping through member directories to fetch and process member data\n",
    "    for member_dir in MEMBERS_DIR_PATH.glob(\"*\"):\n",
    "        if not (member_info_fname := member_dir / \"info.json\").exists():\n",
    "            continue\n",
    "        else:\n",
    "            member_info = json.load(open(member_info_fname, \"r\"))\n",
    "        (\n",
    "            education_experience_df,\n",
    "            social_links,\n",
    "            current_project_title,\n",
    "        ) = parse_member_data(member_dir)\n",
    "        current_academic_role, is_current_member = extract_member_academic_role(\n",
    "            education_experience_df\n",
    "        )\n",
    "        first_name = member_info[\"first_name\"]\n",
    "        last_name = member_info[\"last_name\"]\n",
    "        nickname = member_info.get(\"nick_name\", None)\n",
    "        member_id = member_info[\"id\"]\n",
    "        image_path = member_info[\"image_path\"]\n",
    "        cover_image_path = member_info[\"cover_image_path\"]\n",
    "\n",
    "        name = f\"{nickname if nickname else first_name} {last_name}\"\n",
    "\n",
    "        member_data = {\n",
    "            \"name\": name,\n",
    "            \"academic_role\": current_academic_role,\n",
    "            \"id\": member_id,\n",
    "            \"current_project_title\": current_project_title,\n",
    "            \"image_path\": image_path,\n",
    "            \"cover_image_path\": cover_image_path,\n",
    "        }\n",
    "\n",
    "        if social_links is not None:\n",
    "            member_data.update(social_links)\n",
    "\n",
    "        if is_current_member:\n",
    "            current_people_page_list.append(member_data)\n",
    "        else:\n",
    "            alumni_people_page_list.append(member_data)\n",
    "\n",
    "    return current_people_page_list, alumni_people_page_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../group-data/members/jack_o_brien/jsons/experiences.json does not exist\n",
      "../../group-data/members/hayden_monk/jsons/experiences.json does not exist\n",
      "../../group-data/members/vicente_amado/jsons/experiences.json does not exist\n",
      "../../group-data/members/yuki_matsumura/jsons/experiences.json does not exist\n",
      "../../group-data/members/sona_chitchyan/jsons/education.json does not exist\n",
      "../../group-data/members/alexander_grunewald/jsons/experiences.json does not exist\n",
      "../../group-data/members/benjamin_mellon/jsons/experiences.json does not exist\n",
      "../../group-data/members/benjamin_mellon/jsons/education.json does not exist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'Sofia Biriouk',\n",
       "  'academic_role': 'Undergraduate',\n",
       "  'id': 'sofia_biriouk',\n",
       "  'current_project_title': 'SNR0509-675 Center Investigation',\n",
       "  'image_path': 'media/images/sofia.jpg',\n",
       "  'cover_image_path': 'media/images/cover.jpg',\n",
       "  'website': 'https://sofiabiriouk.github.io',\n",
       "  'github_handle': 'sofiabiriouk',\n",
       "  'linkedin_handle': 'sofia-biriouk-595091199',\n",
       "  'email': 'biriouks@msu.edu',\n",
       "  'orcid': '0009-0004-2531-7423'},\n",
       " {'name': \"Jack O'Brien\",\n",
       "  'academic_role': 'Graduate Student',\n",
       "  'id': 'jack_o_brien',\n",
       "  'current_project_title': None,\n",
       "  'image_path': 'media/images/jack.jpg',\n",
       "  'cover_image_path': 'media/images/cover.jpg',\n",
       "  'website': 'https://jackobrien.info/',\n",
       "  'github_handle': 'Rodot-',\n",
       "  'email': 'jobrien585@gmail.com',\n",
       "  'orcid': '0000-0003-3615-9593'},\n",
       " {'name': 'Josh Shields',\n",
       "  'academic_role': 'Graduate Student',\n",
       "  'id': 'josh_shields',\n",
       "  'current_project_title': 'Surviving Companions Of Supernovae And Stellar Atmospheric Modeling',\n",
       "  'image_path': 'media/images/josh_photo.jpg',\n",
       "  'cover_image_path': 'media/images/cover.jpg',\n",
       "  'website': 'https://jvshields.github.io/',\n",
       "  'github_handle': 'jvshields',\n",
       "  'email': 'shield90@msu.edu',\n",
       "  'orcid': '0000-0002-1560-5286'},\n",
       " {'name': 'Hayden Monk',\n",
       "  'academic_role': 'Undergraduate Student',\n",
       "  'id': 'hayden_monk',\n",
       "  'current_project_title': 'Surviving Companion Search In SNR-0509',\n",
       "  'image_path': 'media/images/hayden.jpg',\n",
       "  'cover_image_path': 'media/images/cover.jpg'},\n",
       " {'name': 'Vicente  Amado Olivo',\n",
       "  'academic_role': 'Graduate Student',\n",
       "  'id': 'vicente_amado',\n",
       "  'current_project_title': 'Development Of A Global Registry For Peer Review In Astrophysics',\n",
       "  'image_path': 'media/images/ESD_headshot.jpg',\n",
       "  'cover_image_path': 'media/images/cover.jpg',\n",
       "  'twitter_handle': 'vamadolivo',\n",
       "  'email': 'amadovic@msu.edu',\n",
       "  'orcid': '0000-0003-2248-0941'},\n",
       " {'name': 'Jing Lu',\n",
       "  'academic_role': 'Postdoctoral Researcher',\n",
       "  'id': 'jing_lu',\n",
       "  'current_project_title': 'Explore the hidden Helium in Type Ic Supernovae',\n",
       "  'image_path': 'media/images/jing.jpg',\n",
       "  'cover_image_path': 'media/images/cover.jpg',\n",
       "  'github_handle': 'DeerWhale',\n",
       "  'linkedin_handle': 'jing-lu-bb89211bb',\n",
       "  'email': 'lujingeve158@gmail.com',\n",
       "  'orcid': '0000-0002-3900-1452'},\n",
       " {'name': 'Yuki Matsumura',\n",
       "  'academic_role': 'Graduate Student',\n",
       "  'id': 'yuki_matsumura',\n",
       "  'current_project_title': 'Type IIP Supernovae As Cosmological Distance Probes',\n",
       "  'image_path': 'media/images/yuki_face.png',\n",
       "  'cover_image_path': 'media/images/cover.jpg',\n",
       "  'github_handle': 'ymatsumu',\n",
       "  'email': 'matsumurayuki725@gmail.com'},\n",
       " {'name': 'Atharva Arya',\n",
       "  'academic_role': 'Research Software Engineer',\n",
       "  'id': 'atharva_arya',\n",
       "  'current_project_title': 'Mitigating open science sustainability issues',\n",
       "  'image_path': 'media/images/atharva.jpg',\n",
       "  'cover_image_path': 'media/images/cover.jpg',\n",
       "  'website': 'https://www.atharvaarya.tech/',\n",
       "  'github_handle': 'atharva-2001',\n",
       "  'twitter_handle': '2001_atharva',\n",
       "  'linkedin_handle': 'atharva-arya',\n",
       "  'email': 'aryaatharva18@gmail.com'},\n",
       " {'name': 'Wolfgang Kerzendorf',\n",
       "  'academic_role': 'Professor',\n",
       "  'id': 'wolfgang_kerzendorf',\n",
       "  'current_project_title': 'Supernovae & Computational Metaresearch',\n",
       "  'image_path': 'media/images/wolfgang.jpg',\n",
       "  'cover_image_path': 'media/images/cover.jpg',\n",
       "  'website': 'https://wolfgangkerzendorf.com',\n",
       "  'github_handle': 'wkerzendorf',\n",
       "  'twitter_handle': 'wkerzendorf',\n",
       "  'linkedin_handle': 'wolfgang-kerzendorf-598a0466',\n",
       "  'email': 'wkerzend@msu.edu',\n",
       "  'orcid': '0000-0002-0479-7235'},\n",
       " {'name': 'Sona Chitchyan',\n",
       "  'academic_role': '',\n",
       "  'id': 'sona_chitchyan',\n",
       "  'current_project_title': 'Enhanced Type IIP Cosmology With Statistics And Machine Learning',\n",
       "  'image_path': 'media/images/sona_photo.jpg',\n",
       "  'cover_image_path': 'media/images/cover.jpg'},\n",
       " {'name': 'Bea Lu',\n",
       "  'academic_role': 'Undergraduate',\n",
       "  'id': 'bea_lu',\n",
       "  'current_project_title': 'Natural Language Processing',\n",
       "  'image_path': 'media/images/bea_lu.jpg',\n",
       "  'cover_image_path': 'media/images/cover.jpg',\n",
       "  'github_handle': 'bumblebealu',\n",
       "  'email': 'lubangji@msu.edu',\n",
       "  'orcid': '0000-0002-3393-2424'},\n",
       " {'name': 'Alexander Grunewald',\n",
       "  'academic_role': 'Undergraduate Student',\n",
       "  'id': 'alexander_grunewald',\n",
       "  'current_project_title': 'Emulator Project',\n",
       "  'image_path': 'media/images/alexander.jpg',\n",
       "  'cover_image_path': 'media/images/cover.jpg',\n",
       "  'github_handle': 'AlexanderGrunewald',\n",
       "  'linkedin_handle': 'alexander-grunewald-8007a51b5',\n",
       "  'email': 'grunew14@msu.edu'},\n",
       " {'name': 'Harshul Gupta',\n",
       "  'academic_role': 'Research Software Engineer',\n",
       "  'id': 'harshul_gupta',\n",
       "  'current_project_title': 'Website Development',\n",
       "  'image_path': 'media/images/harshul.jpeg',\n",
       "  'cover_image_path': 'media/images/cover.jpg',\n",
       "  'website': 'https://www.harshulgupta.in',\n",
       "  'github_handle': 'harshulgupt',\n",
       "  'twitter_handle': 'harshulgupt',\n",
       "  'linkedin_handle': 'harshulgupt',\n",
       "  'email': 'harshulgupt@gmail.com'},\n",
       " {'name': 'Erin Visser',\n",
       "  'academic_role': 'Undergraduate Student',\n",
       "  'id': 'erin_visser',\n",
       "  'current_project_title': None,\n",
       "  'image_path': 'media/images/erin_visser_website_pic.jpg',\n",
       "  'cover_image_path': 'media/images/cover.jpg',\n",
       "  'github_handle': 'erinvisser',\n",
       "  'email': 'visserer@msu.edu',\n",
       "  'orcid': '0009-0001-8470-275X'},\n",
       " {'name': 'Andrew Fullard',\n",
       "  'academic_role': 'Research Consultant',\n",
       "  'id': 'andrew_fullard',\n",
       "  'current_project_title': 'Inferring explosion conditions from late-time Type Ia supernova spectra',\n",
       "  'image_path': 'media/images/me.jpg',\n",
       "  'cover_image_path': 'media/images/cover.jpg',\n",
       "  'github_handle': 'andrewfullard',\n",
       "  'twitter_handle': 'astrofullard',\n",
       "  'linkedin_handle': 'andrew-fullard-a9a487168/',\n",
       "  'email': 'fullarda@msu.edu',\n",
       "  'orcid': '0000-0001-7343-1678'},\n",
       " {'name': 'Jaladh Singhal',\n",
       "  'academic_role': 'Visualization Consultant',\n",
       "  'id': 'jaladh_singhal',\n",
       "  'current_project_title': 'Space Tools',\n",
       "  'image_path': 'media/images/jaladh.jpg',\n",
       "  'cover_image_path': 'media/images/cover.jpg'},\n",
       " {'name': 'Tripp Dow',\n",
       "  'academic_role': '',\n",
       "  'id': 'richard_dow',\n",
       "  'current_project_title': 'Identifying Worldwide Astrophysicists From Scientific Literature',\n",
       "  'image_path': 'media/images/richard.jpg',\n",
       "  'cover_image_path': 'media/images/cover.jpg',\n",
       "  'github_handle': 'prettytrippy',\n",
       "  'email': 'dow00019@umn.edu',\n",
       "  'orcid': '0009-0007-2842-1690'},\n",
       " {'name': 'Cecelia Powers',\n",
       "  'academic_role': 'Undergraduate',\n",
       "  'id': 'cecelia_powers',\n",
       "  'current_project_title': None,\n",
       "  'image_path': '../../website_files/images/me.jpeg',\n",
       "  'cover_image_path': 'media/images/cover.jpg'},\n",
       " {'name': 'Anirban  Dutta',\n",
       "  'academic_role': 'Postdoctoral Researcher',\n",
       "  'id': 'anirban_dutta',\n",
       "  'current_project_title': 'Non-LTE modeling of supernova spectra',\n",
       "  'image_path': 'media/images/anirban_dutta.jpg',\n",
       "  'cover_image_path': 'media/images/cover.jpg',\n",
       "  'website': 'https://sites.google.com/view/anirbaniamdutta',\n",
       "  'github_handle': 'Knights-Templars',\n",
       "  'twitter_handle': 'Anirban29Dutta',\n",
       "  'linkedin_handle': 'anirban-dutta-6a0377238',\n",
       "  'email': 'anirbaniamdutta@gmail.com',\n",
       "  'orcid': '0000-0002-7708-3831'},\n",
       " {'name': 'Iliomar Rodriguez-Ramos',\n",
       "  'academic_role': '',\n",
       "  'id': 'iliomar_rodriguez_ramos',\n",
       "  'current_project_title': 'Exploring The Complex Structures Of Ancient Stars',\n",
       "  'image_path': 'media/images/iliomar_ft.jpg',\n",
       "  'cover_image_path': 'media/images/cover.jpg'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "current_people_page_list, alumni_people_page_list = fetch_member_data()\n",
    "display(current_people_page_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "create_page(\n",
    "    \"people.html.j2\",\n",
    "    \"People.html\",\n",
    "    general=data[\"general\"],\n",
    "    current_members=current_people_page_list,\n",
    "    alumni_members=alumni_people_page_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contact Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "create_page(\n",
    "    \"contact.html.j2\", \"Contact.html\", general=data[\"general\"], contact=data[\"contact\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_page(\n",
    "    \"support.html.j2\", \"Support.html\", general=data[\"general\"], support=data[\"support\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Front Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For adding more columns in dataframe to render front pages and individual article pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "columns_extended = ARTICLE_METADATA_FIELDS + [\"author_id\"]\n",
    "content_df = load_content_from_files(columns_extended)\n",
    "research_content_df = content_df[content_df[\"category\"] != \"News\"].sort_values(\n",
    "    by=[\"category\", \"date\"], ascending=[True, False]\n",
    ")\n",
    "latest_content_df = get_latest_content_df(content_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "create_page(\n",
    "    \"research.html.j2\",\n",
    "    \"Research.html\",\n",
    "    general=data[\"general\"],\n",
    "    content=research_content_df,\n",
    "    research=data[\"research\"],\n",
    "    current_members=current_people_page_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sub_research_template = environment.get_template(\"sub_research_frontpage.html.j2\")\n",
    "\n",
    "\n",
    "for category in content_df.loc[content_df.category != \"News\", \"category\"].unique():\n",
    "    sub_research_content = sub_research_template.render(\n",
    "        general=data[\"general\"],\n",
    "        research=data[\"research\"],\n",
    "        content=latest_content_df,\n",
    "        category=category,\n",
    "        current_members=current_people_page_list,\n",
    "    )\n",
    "    folder_path = f\"{HOSTING_PATH}/sub_research/{page_link(category.lower())}\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    with open(f\"{folder_path}.html\", mode=\"w\", encoding=\"utf-8\") as sub_research:\n",
    "        sub_research.write(sub_research_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
