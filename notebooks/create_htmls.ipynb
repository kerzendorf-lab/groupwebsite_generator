{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### This notebook consist of code for creating the html files for the website each time data is updated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "from jinja2.exceptions import UndefinedError\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "GROUP_DATA_DIR = Path(\"../..//group-data\")\n",
    "MEMBERS_DIR_PATH = GROUP_DATA_DIR / \"members/\"\n",
    "WEBSITE_DATA_PATH = GROUP_DATA_DIR / \"website_data/\"\n",
    "CONTENT_DIR_PATH = WEBSITE_DATA_PATH / \"content\"\n",
    "TEMPLATE_DIR_PATH = GROUP_DATA_DIR.parent / \"groupwebsite_generator\" / \"templates\"\n",
    "HOSTING_PATH = GROUP_DATA_DIR.parent / \"kerzendorf-group.github.io\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# List of JSON files to be processed\n",
    "JSON_FILES_TO_LOAD = [\n",
    "    \"general\",\n",
    "    \"homepage\",\n",
    "    \"research\",\n",
    "    \"support\",\n",
    "    \"contact\",\n",
    "]\n",
    "# Needed columns for homepage\n",
    "ARTICLE_METADATA_FIELDS = [\n",
    "    \"article_id\",\n",
    "    \"category\",\n",
    "    \"date\",\n",
    "    \"tags\",\n",
    "    \"title\",\n",
    "    \"cover_image\",\n",
    "    \"short_description\",\n",
    "]\n",
    "# Groups and institution used in filtering data\n",
    "GROUP_FILTER = [\"DTI\", \"TARDIS\", \"ICER\", \"kerzendorf\"]\n",
    "INSTITUTION_FILTER = \"Michigan State University\"\n",
    "\n",
    "# Map roles to standardized roles for consistency\n",
    "ROLE_MAP = {\n",
    "    \"Assistant Professor\": \"Professor\",\n",
    "    \"Professor\": \"Professor\",\n",
    "    \"Visualization Consultant\": \"Visualization Consultant\",\n",
    "    \"Research Consultant\": \"Research Consultant\",\n",
    "    \"Research Software Engineer\": \"Research Software Engineer\",\n",
    "    \"Professorial Assistant\": \"Undergraduate\",\n",
    "    \"Visiting Researcher\": \"Postdoctoral Researcher\",\n",
    "    \"Postdoctoral Researcher\": \"Postdoctoral Researcher\",\n",
    "}\n",
    "\n",
    "# Map degrees to standardized academic levels\n",
    "DEGREE_MAP = {\n",
    "    \"Masters\": \"Graduate Student\",\n",
    "    \"PhD\": \"Postdoctorate\",  #  if end_date is present\n",
    "    \"Bachelors\": \"Graduate Student\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Function to create proper HTML file names by replacing spaces with underscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def page_link(a):\n",
    "    \"\"\"Return the HTML file name after replacing blank spaces(\" \") with underscores(\"-\")\"\"\"\n",
    "    return a.replace(\" \", \"_\") if \" \" in a else a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Creating an instance of the Environment class that looks for templates. Page_link is set to the global variable so that it can be accessed by all templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "environment = Environment(\n",
    "    loader=FileSystemLoader(TEMPLATE_DIR_PATH), extensions=[\"jinja2.ext.loopcontrols\"]\n",
    ")\n",
    "environment.globals[\"page_link\"] = page_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for looping through JSON files and loading their content into the 'data' dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def loading_json_files(json_data_list):\n",
    "    \"\"\"\n",
    "    Load data from JSON files specified in a list of file names.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    json_data_list : list of str\n",
    "        A list of file names (without extension) to load as JSON.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary where keys are file names and values are the corresponding JSON data.\n",
    "\n",
    "    Raises:\n",
    "    ------\n",
    "    FileNotFoundError:\n",
    "        If a specified file does not exist.\n",
    "    json.JSONDecodeError:\n",
    "        If there's an issue decoding the JSON content from a file.\n",
    "\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for data_id in json_data_list:\n",
    "        data_path = WEBSITE_DATA_PATH / f\"{data_id}.json\"\n",
    "\n",
    "        try:\n",
    "            with open(data_path, \"r\") as json_file:\n",
    "                data[json_file] = json.load(json_file)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File '{json_file}.json' not found.\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON in '{json_file}.json'.\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create a page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_page(template, html, **kwargs):\n",
    "    \"\"\"\n",
    "    Create an HTML page using a Jinja2 template and save it to a specified path.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    template : str\n",
    "        The filename of the Jinja2 template to be used.\n",
    "    html : str\n",
    "        The filename of the HTML file to be generated.\n",
    "    **kwargs : dict\n",
    "        Additional keyword arguments to be passed to the Jinja2 template for rendering.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    page_template = environment.get_template(template)\n",
    "    page_html_path = HOSTING_PATH / html\n",
    "    page_content = page_template.render(**kwargs)\n",
    "    with open(page_html_path, mode=\"w\", encoding=\"utf-8\") as page:\n",
    "        page.write(page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataframes for articles which can be updated further "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_content_from_files(columns):\n",
    "    \"\"\"\n",
    "    Load content data from JSON files into a Pandas DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    columns : list of str\n",
    "        A list of column names to extract from the JSON files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A DataFrame containing the specified columns from the loaded JSON files.\n",
    "\n",
    "    \"\"\"\n",
    "    content_data = {col: [] for col in columns}\n",
    "\n",
    "    for json_file in os.listdir(CONTENT_DIR_PATH):\n",
    "        if json_file.endswith(\".json\"):\n",
    "            json_path = os.path.join(CONTENT_DIR_PATH, json_file)\n",
    "            with open(json_path, \"r\") as file:\n",
    "                info = json.load(file)\n",
    "                # Only load those articles where display is True\n",
    "                if info.get(\"display\"):\n",
    "                    for col in columns:\n",
    "                        content_data[col].append(info.get(col))\n",
    "\n",
    "    content_df = pd.DataFrame(content_data)\n",
    "    content_df[\"date\"] = pd.to_datetime(content_df[\"date\"], format=\"%m-%d-%Y\")\n",
    "    return content_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the Latest Content for Each Category from a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_latest_content_df(content_df):\n",
    "    \"\"\"\n",
    "    Extract the latest content for each category from a DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    content_df : pandas.DataFrame\n",
    "        The input DataFrame containing content information.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A DataFrame containing the latest content for each category.\n",
    "\n",
    "    \"\"\"\n",
    "    # Sort the entire DataFrame by \"category\" and \"date\" in descending order\n",
    "    sorted_content_df = content_df.sort_values(\n",
    "        by=[\"category\", \"date\"], ascending=[True, False]\n",
    "    )\n",
    "\n",
    "    # Get the first row for each category using groupby and head\n",
    "    latest_content_df = sorted_content_df.groupby(\"category\").head(1).copy()\n",
    "    latest_content_df[\"date\"] = pd.to_datetime(\n",
    "        latest_content_df[\"date\"], format=\"%m-%d-%Y\"\n",
    "    )\n",
    "    latest_content_df = latest_content_df.sort_values(by=\"date\", ascending=False)\n",
    "\n",
    "    return latest_content_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing List Of JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Call\n",
    "data = loading_json_files(JSON_FILES_TO_LOAD)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homepage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing selected columns for Homepage only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_df = load_content_from_files(ARTICLE_METADATA_FIELDS)\n",
    "latest_content_df = get_latest_content_df(content_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_page(\n",
    "    \"homepage.html.j2\",\n",
    "    \"Index.html\",\n",
    "    general=data[\"general\"],\n",
    "    homepage=data[\"homepage\"],\n",
    "    recent_content=latest_content_df.to_dict(orient=\"records\"),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### People Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering based on group and institution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def filter_edu_exp_data(df, valid_groups,valid_institution):\n",
    "    \"\"\"\n",
    "    Filter education and experience data based on specified criteria.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing education and experience data.\n",
    "    valid_groups : list\n",
    "        List of valid groups to include in the filtered data.\n",
    "    valid_institution : str\n",
    "        The valid institution to include in the filtered data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A filtered DataFrame containing only the rows that meet the specified criteria.\n",
    "    \"\"\"\n",
    "    group_mask = False\n",
    "    institution_mask = False\n",
    "\n",
    "    # Check if 'group' column exists and update mask accordingly\n",
    "    if \"group\" in df.columns:\n",
    "        group_mask = df[\"group\"].isin(valid_groups)\n",
    "\n",
    "    # Check if 'institution' column exists and update mask accordingly\n",
    "    if \"institution\" in df.columns:\n",
    "        institution_mask = df[\"institution\"] == valid_institution\n",
    "\n",
    "    final_mask = group_mask | institution_mask\n",
    "    return df[final_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to load education data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_education_experience_data(directory):\n",
    "    \"\"\"\n",
    "    Load education and experience data from JSON files, filter based on criteria, and perform preprocessing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    directory : str or pathlib.Path\n",
    "        The directory path containing \"experiences.json\" and \"education.json\" files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A DataFrame containing filtered and preprocessed education and experience data.\n",
    "    \"\"\"\n",
    "    filtered_records = []\n",
    "    file_names = [\"experiences.json\", \"education.json\"]\n",
    "    for file_name in file_names:\n",
    "        file_path = directory / file_name\n",
    "        if file_path.exists():\n",
    "            # Reading JSON data directly into a DataFrame\n",
    "            records = pd.read_json(file_path)\n",
    "\n",
    "            # filtering based on group and institution\n",
    "            valid_records = filter_edu_exp_data(records, GROUP_FILTER, INSTITUTION_FILTER)\n",
    "\n",
    "            filtered_records.append(valid_records)\n",
    "        else:\n",
    "            print(f\"{file_path} does not exist\")\n",
    "\n",
    "    if filtered_records:\n",
    "        combined_records = pd.concat(filtered_records, ignore_index=True)\n",
    "    else:\n",
    "        combined_records = pd.DataFrame()\n",
    "\n",
    "    # if start_date column exists, fill with NaN if it doesn't\n",
    "    if \"start_date\" not in combined_records:\n",
    "        combined_records[\"start_date\"] = pd.NaT\n",
    "\n",
    "    # Convert start_date to datetime format\n",
    "    combined_records[\"start_date\"] = pd.to_datetime(combined_records[\"start_date\"], errors=\"coerce\")\n",
    "\n",
    "    # Sort the DataFrame based on start_date\n",
    "    combined_records = combined_records.sort_values(by=\"start_date\", ascending=False)\n",
    "    return combined_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function load social links directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_social_links(social_dir):\n",
    "    \"\"\"\n",
    "    Load social links from a JSON file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    social_dir : str or pathlib.Path\n",
    "        The directory path containing the \"social_links.json\" file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict or None\n",
    "        A dictionary containing social links or None if the file doesn't exist.\n",
    "    \"\"\"\n",
    "    social_links = None\n",
    "    social_links_file_path = social_dir / \"social_links.json\"\n",
    "    if social_links_file_path.exists():\n",
    "        with open(social_links_file_path, \"r\") as f:\n",
    "            social_links = json.load(f)\n",
    "    return social_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to load topmost project title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_latest_project_title(project_dir):\n",
    "    \"\"\"\n",
    "    Load the title of the topmost project from a JSON file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    project_dir : str or pathlib.Path\n",
    "        The directory path containing the \"projects.json\" file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str or None\n",
    "        The title of the topmost project or None if the file doesn't exist or is empty.\n",
    "    \"\"\"\n",
    "    projects_file_path = project_dir / \"projects.json\"\n",
    "    topmost_project_title = None\n",
    "    if projects_file_path.exists():\n",
    "        projects_df = pd.read_json(projects_file_path)\n",
    "        if not projects_df.empty:\n",
    "            # Fetching the project title from the first row of the DataFrame\n",
    "            topmost_project_title = projects_df.iloc[0].get(\"project_title\")\n",
    "    return topmost_project_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funtion to parse member data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def parse_member_data(member_dir):\n",
    "    \"\"\"\n",
    "    Parse member-related data from JSON files in the specified directory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    member_dir : str or pathlib.Path\n",
    "        The directory path containing member-related JSON files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        A tuple containing education and experience DataFrame, social links dictionary,\n",
    "        and the title of the current project.\n",
    "    \"\"\"\n",
    "    member_json_dir = member_dir / \"jsons\"\n",
    "    education_experience_df = load_education_experience_data(member_json_dir)\n",
    "    current_project_title = load_latest_project_title(member_json_dir)\n",
    "    social_links = load_social_links(member_json_dir)\n",
    "\n",
    "    return education_experience_df, social_links, current_project_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to extract academic roles from education and experience data\n",
    "def extract_member_academic_role(education_experience_df):\n",
    "    \"\"\"\n",
    "    Extract the current academic role of a member based on education and experience data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    education_experience_df : pandas.DataFrame\n",
    "        DataFrame containing education and experience data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[str, bool]\n",
    "        A tuple containing:\n",
    "        - str: The current academic role of the member.\n",
    "        - bool: True if the member is currently active, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if these columns exist in dataframe\n",
    "    for column in [\"end_date\", \"group\", \"institution\"]:\n",
    "        if column not in education_experience_df.columns:\n",
    "            education_experience_df[column] = None\n",
    "\n",
    "    current_academic_role = None\n",
    "\n",
    "    for _, row in education_experience_df.iterrows():\n",
    "        role = row.get(\"role\", None)\n",
    "        degree = row.get(\"degree\", None)\n",
    "\n",
    "        if not current_academic_role:\n",
    "            current_academic_role = ROLE_MAP.get(role, \"\")\n",
    "\n",
    "            if degree == \"PhD\" and pd.isna(row[\"end_date\"]):\n",
    "                current_academic_role = \"Graduate Student\"  # if end_date is NaN\n",
    "            elif degree == \"Bachelors\" and pd.isna(row[\"end_date\"]):\n",
    "                current_academic_role = \"Undergraduate Student\"\n",
    "            elif not current_academic_role and degree in DEGREE_MAP:\n",
    "                current_academic_role = DEGREE_MAP[degree]\n",
    "\n",
    "    # Check for end dates outside the loop\n",
    "    has_end_date = all(\n",
    "        not pd.isna(date) for date in education_experience_df[\"end_date\"]\n",
    "    )\n",
    "    is_current_member = not has_end_date\n",
    "\n",
    "    return current_academic_role, is_current_member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lists to store data for current and alumni members\n",
    "def fetch_member_data():\n",
    "    \"\"\"\n",
    "    Fetch and process member data from directories in the specified members' directory.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[list, list]\n",
    "        A tuple containing two lists:\n",
    "        1. List of dictionaries representing current members' data.\n",
    "        2. List of dictionaries representing alumni members' data.\n",
    "\n",
    "    \"\"\"\n",
    "    current_people_page_list = []\n",
    "    alumni_people_page_list = []\n",
    "    # Looping through member directories to fetch and process member data\n",
    "    for member_dir in MEMBERS_DIR_PATH.glob(\"*\"):\n",
    "        if not (member_info_fname := member_dir / \"info.json\").exists():\n",
    "            continue\n",
    "        else:\n",
    "            member_info = json.load(open(member_info_fname, \"r\"))\n",
    "        (\n",
    "            education_experience_df,\n",
    "            social_links,\n",
    "            current_project_title,\n",
    "        ) = parse_member_data(member_dir)\n",
    "        current_academic_role, is_current_member = extract_member_academic_role(\n",
    "            education_experience_df\n",
    "        )\n",
    "        first_name = member_info[\"first_name\"]\n",
    "        last_name = member_info[\"last_name\"]\n",
    "        nickname = member_info.get(\"nick_name\", None)\n",
    "        id = member_info[\"id\"]\n",
    "        image_path = member_info[\"image_path\"]\n",
    "        cover_image_path = member_info[\"cover_image_path\"]\n",
    "\n",
    "        name = f\"{nickname if nickname else first_name} {last_name}\"\n",
    "\n",
    "        member_data = {\n",
    "            \"name\": name,\n",
    "            \"academic_role\": current_academic_role,\n",
    "            \"id\": id,\n",
    "            \"current_project_title\": current_project_title,\n",
    "            \"image_path\": image_path,\n",
    "            \"cover_image_path\": cover_image_path,\n",
    "        }\n",
    "\n",
    "        if social_links is not None:\n",
    "            member_data.update(social_links)\n",
    "\n",
    "        if is_current_member:\n",
    "            current_people_page_list.append(member_data)\n",
    "        else:\n",
    "            alumni_people_page_list.append(member_data)\n",
    "\n",
    "    return current_people_page_list, alumni_people_page_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MEMBERS_DIR_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m current_people_page_list, alumni_people_page_list \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_member_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m, in \u001b[0;36mfetch_member_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m alumni_people_page_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Looping through member directories to fetch and process member data\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m member_dir \u001b[38;5;129;01min\u001b[39;00m \u001b[43mMEMBERS_DIR_PATH\u001b[49m\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (member_info_fname \u001b[38;5;241m:=\u001b[39m member_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfo.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MEMBERS_DIR_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "current_people_page_list, alumni_people_page_list = fetch_member_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_page' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcreate_page\u001b[49m(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpeople.html.j2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPeople.html\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     general\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneral\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      5\u001b[0m     current_members\u001b[38;5;241m=\u001b[39mcurrent_people_page_list,\n\u001b[1;32m      6\u001b[0m     alumni_members\u001b[38;5;241m=\u001b[39malumni_people_page_list,\n\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_page' is not defined"
     ]
    }
   ],
   "source": [
    "create_page(\n",
    "    \"people.html.j2\",\n",
    "    \"People.html\",\n",
    "    general=data[\"general\"],\n",
    "    current_members=current_people_page_list,\n",
    "    alumni_members=alumni_people_page_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contact Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "create_page(\n",
    "    \"contact.html.j2\", \"Contact.html\", general=data[\"general\"], contact=data[\"contact\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "create_page(\n",
    "    \"support.html.j2\", \"Support.html\", general=data[\"general\"], support=data[\"support\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Front Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For adding more columns in dataframe to render front pages and individual article pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "columns_extended = ARTICLE_METADATA_FIELDS + [\"author_id\"]\n",
    "content_df = load_content_from_files(columns_extended)\n",
    "research_content_df = content_df[content_df[\"category\"] != \"News\"].sort_values(\n",
    "    by=[\"category\", \"date\"], ascending=[True, False]\n",
    ")\n",
    "latest_content_df = get_latest_content_df(content_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "create_page(\n",
    "    \"research.html.j2\",\n",
    "    \"Research.html\",\n",
    "    general=data[\"general\"],\n",
    "    content=research_content_df,\n",
    "    research=data[\"research\"],\n",
    "    current_members=current_people_page_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_research_template = environment.get_template(\"sub_research_frontpage.html.j2\")\n",
    "\n",
    "\n",
    "for category in content_df.loc[content_df.category != \"News\", \"category\"].unique():\n",
    "    sub_research_content = sub_research_template.render(\n",
    "        general=data[\"general\"],\n",
    "        research=data[\"research\"],\n",
    "        content=latest_content_df,\n",
    "        category=category,\n",
    "        current_members=current_people_page_list,\n",
    "    )\n",
    "    folder_path = f\"{HOSTING_PATH}/sub_research/{page_link(category.lower())}\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    with open(f\"{folder_path}.html\", mode=\"w\", encoding=\"utf-8\") as sub_research:\n",
    "        sub_research.write(sub_research_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
