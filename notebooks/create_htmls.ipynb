{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### This notebook consist of code for creating the html files for the website each time data is updated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.145701234Z",
     "start_time": "2023-11-21T07:07:35.993568325Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from datetime import datetime, date\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.276371007Z",
     "start_time": "2023-11-21T07:07:36.010519700Z"
    }
   },
   "outputs": [],
   "source": [
    "GROUP_DATA_DIR = Path(\"../../group-data\")\n",
    "TEMPLATE_DIR_PATH = GROUP_DATA_DIR.parent / \"groupwebsite_generator\" / \"templates\"\n",
    "WEBSITE_DATA_PATH = GROUP_DATA_DIR / \"website_data/\"\n",
    "HOSTING_PATH = GROUP_DATA_DIR.parent / \"kerzendorf-lab.github.io\"\n",
    "ARTICLE_DIR_PATH = Path(\"../../research_news/articles\")\n",
    "ARTICLE_IMAGE_DESTINATION_DIR = (HOSTING_PATH / \"website_files\" / \"images\" / \"article_content\")\n",
    "MEMBERS_DIR_PATH = GROUP_DATA_DIR / \"members/\"\n",
    "SUB_RESEARCH_PATH = HOSTING_PATH / \"sub_research\"\n",
    "OPPORTUNITIES_PATH = WEBSITE_DATA_PATH / \"content\" / \"opportunities.json\"\n",
    "ROLE_HIERARCHY_PATH = WEBSITE_DATA_PATH / \"role_hierarchy.json\"\n",
    "GENERAL_TAGS = [\n",
    "    \"Paper\",\n",
    "    \"Poster\", \n",
    "    \"Talk\",\n",
    "    \"Award\",\n",
    "    \"New Team Member\",\n",
    "    \"PhD\",\n",
    "    \"Conference\",\n",
    "    \"Undergraduate\",\n",
    "    \"Event\",\n",
    "    \"Achievement\"\n",
    "]\n",
    "\n",
    "# Define tag colors mapping\n",
    "TAG_COLORS = {\n",
    "    'paper': '#FF6B6B',  # Coral red\n",
    "    'poster': '#4ECDC4', # Turquoise\n",
    "    'talk': '#45B7D1',   # Light blue\n",
    "    'award': '#96CEB4',  # Sage green\n",
    "    'new team member': '#FFBE0B', # Golden yellow\n",
    "    'phd': '#9B5DE5',    # Purple\n",
    "    'conference': '#FF006E', # Pink\n",
    "    'undergraduate': '#8338EC', # Violet\n",
    "    'event': '#3A86FF',  # Royal blue\n",
    "    'achievement': '#FB5607', # Orange\n",
    "    'astrophysics': '#2EC4B6', # Teal\n",
    "    'machine learning': '#FF9F1C', # Light orange\n",
    "    'software': '#E71D36', # Bright red\n",
    "    'research': '#011627', # Dark blue\n",
    "    'news': '#41EAD4'    # Cyan\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Setting up jinja environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.311056453Z",
     "start_time": "2023-11-21T07:07:36.038221785Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to create proper HTML file names by replacing spaces with underscores\n",
    "def page_link(a):\n",
    "    \"\"\"Return the HTML file name after replacing blank spaces(\" \") with underscores(\"-\")\"\"\"\n",
    "    return a.replace(\" \", \"_\") if \" \" in a else a\n",
    "\n",
    "# Function to get tag color, returns a default if tag not in mapping\n",
    "def get_tag_color(tag):\n",
    "    \"\"\"Get color for a specific tag, with fallback to default\"\"\"\n",
    "    tag = tag.lower()\n",
    "    return TAG_COLORS.get(tag, '#6c757d')  # Default gray if tag not found\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = Environment(\n",
    "    loader=FileSystemLoader(TEMPLATE_DIR_PATH), extensions=[\"jinja2.ext.loopcontrols\", \"jinja2.ext.do\"]\n",
    ")\n",
    "environment.globals[\"page_link\"] = page_link\n",
    "# Add tag colors to jinja environment globals\n",
    "environment.globals['tag_colors'] = TAG_COLORS\n",
    "environment.globals['get_tag_color'] = get_tag_color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Processing Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.308005773Z",
     "start_time": "2023-11-21T07:07:36.024555660Z"
    }
   },
   "outputs": [],
   "source": [
    "# Needed columns for articles\n",
    "ARTICLE_METADATA_FIELDS = [\n",
    "    \"article_id\",\n",
    "    \"category\",\n",
    "    \"date\",\n",
    "    \"tags\",\n",
    "    \"title\",\n",
    "    \"cover_image\",\n",
    "    \"short_description\"\n",
    "]\n",
    "# Groups and institution used in filtering data\n",
    "GROUP_FILTER = [\"DTI\", \"TARDIS\", \"ICER\", \"kerzendorf\"]\n",
    "INSTITUTION_FILTER = \"Michigan State University\"\n",
    "\n",
    "# Map roles to standardized roles for consistency\n",
    "ROLE_MAP = {\n",
    "    \"Assistant Professor\": \"Professor\",\n",
    "    \"Professorial Assistant\": \"Undergraduate Student\",\n",
    "    \"Visiting Researcher\": \"Postdoctoral Researcher\"\n",
    "}\n",
    "\n",
    "# Map degrees to standardized academic levels\n",
    "DEGREE_MAP = {\n",
    "    \"Masters\": \"Graduate Student\",\n",
    "    \"PhD\": \"Postdoctorate\",  #  if end_date is present\n",
    "    \"Bachelors\": \"Undergraduate Student\",\n",
    "}\n",
    "\n",
    "INDIVIDUAL_MEMBER_SECTION_MAP = {\n",
    "    \"education\": \"Education\",\n",
    "    \"experiences\": \"Experience\",\n",
    "    \"projects\": \"Projects\",\n",
    "    \"awards\": \"Awards & Recognition\",\n",
    "    \"outreach\": \"Outreach Programs\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Functions for Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_website_data(file_to_load):\n",
    "    \"\"\"\n",
    "    Load data from JSON files specified in a list of file names.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    json_data_list : list of str\n",
    "        A list of file names (without extension) to load as JSON.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary where keys are file names and values are the corresponding JSON data.\n",
    "\n",
    "    Raises:\n",
    "    ------\n",
    "    FileNotFoundError:\n",
    "        If a specified file does not exist.\n",
    "    json.JSONDecodeError:\n",
    "        If there's an issue decoding the JSON content from a file.\n",
    "\n",
    "    \"\"\"\n",
    "    loaded_data = {}\n",
    "    file_matches = WEBSITE_DATA_PATH/ f\"{file_to_load}.json\"\n",
    "    if file_matches:\n",
    "        try:\n",
    "            with open(file_matches, \"r\") as json_file:\n",
    "                loaded_data = json.load(json_file)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON in '{file_matches}'.\")\n",
    "    else:\n",
    "        print(f\"File '{file_to_load}.json' not found.\")\n",
    "\n",
    "    return loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_member_data_jsons(file_to_read):\n",
    "    member_data_list = []\n",
    "    member_data_df = pd.DataFrame([])\n",
    "    for single_info_file_path in MEMBERS_DIR_PATH.glob(\"*/info.json\"):\n",
    "        with open(single_info_file_path, \"r\") as f_info:\n",
    "            member_data = json.load(f_info)\n",
    "        member_unique_id = member_data[\"id\"]\n",
    "        file_to_read_path = single_info_file_path.parent / \"jsons\" / file_to_read\n",
    "\n",
    "        if file_to_read_path.exists():\n",
    "            with file_to_read_path.open(\"r\") as f_data:\n",
    "                member_other_data = json.load(f_data)\n",
    "            for entry in member_other_data:\n",
    "                entry[\"id\"] = member_unique_id\n",
    "            member_data_list.append(\n",
    "                pd.DataFrame(member_other_data)\n",
    "            )\n",
    "        # else:\n",
    "        #     data_path_in_kl = KERZENDORF_GROUP_DATA / \"members\" / member_unique_id / \"jsons\" / file_to_read\n",
    "        #     if data_path_in_kl.exists():\n",
    "        #         with data_path_in_kl.open(\"r\") as data_file:\n",
    "        #             member_other_data_kl = json.load(data_file)\n",
    "        #         for entry in member_other_data_kl:\n",
    "        #             entry[\"id\"] = member_unique_id\n",
    "        #         member_data_list.append(\n",
    "        #             pd.DataFrame(member_other_data_kl)\n",
    "        #         )\n",
    "\n",
    "    if member_data_list:\n",
    "        member_data_df = pd.concat(\n",
    "            member_data_list, ignore_index=True\n",
    "        )\n",
    "        member_data_df.set_index(\"id\", inplace=True)\n",
    "\n",
    "    return member_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_new_image_path(source_dir, old_image_path):\n",
    "    article_image_path = source_dir.parent / \"media\" / \"images\"\n",
    "    image_source = article_image_path / old_image_path.name\n",
    "    image_destination = ARTICLE_IMAGE_DESTINATION_DIR / old_image_path.name\n",
    "    website_files_index = image_destination.parts.index(\"website_files\")\n",
    "    new_image_path = Path(*image_destination.parts[website_files_index:])\n",
    "    shutil.copy2(image_source, image_destination)\n",
    "    return str(new_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# DataFrame Creation and Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataframes for articles which can be updated further "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.355136270Z",
     "start_time": "2023-11-21T07:07:36.080422459Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading all articles\n",
    "article_content_list = []\n",
    "today = date.today()\n",
    "for content_file_name in ARTICLE_DIR_PATH.rglob('info.json'):\n",
    "    with open(content_file_name, \"r\") as fcontent:\n",
    "        article_content = json.load(fcontent)\n",
    "    today_datetime = datetime.combine(today, datetime.min.time())\n",
    "    article_date = datetime.strptime(article_content[\"date\"], \"%m-%d-%Y\")\n",
    "    if \"kg\" in article_content[\"platforms\"] and article_date <= today_datetime:\n",
    "        image_path = Path(article_content[\"cover_image\"])\n",
    "        article_content[\"cover_image\"] = set_new_image_path(content_file_name, image_path)\n",
    "        for content_key, content_value in article_content[\"content\"].items():\n",
    "            if \"img\" in content_key:\n",
    "                new_content_value = set_new_image_path(content_file_name, Path(content_value))\n",
    "                article_content[\"content\"][content_key] = new_content_value\n",
    "        article_content_list.append(article_content)\n",
    "article_content_df = pd.DataFrame(article_content_list)\n",
    "\n",
    "article_content_df[\"date\"] = pd.to_datetime(\n",
    "    article_content_df[\"date\"], format=\"%m-%d-%Y\"\n",
    ")\n",
    "\n",
    "article_content_df[\"cover_image_height\"] = (\n",
    "    article_content_df[\"cover_image_height\"].fillna(\"330px\").replace(\"\", \"330px\")\n",
    ")\n",
    "article_content_df[\"cover_image_width\"] = (\n",
    "    article_content_df[\"cover_image_width\"].fillna(\"520px\").replace(\"\", \"520px\")\n",
    ")\n",
    "\n",
    "#THis line is only for kerzendorf lab and is not needed on dti\n",
    "article_content_df[\"category\"] = article_content_df[\"category\"].replace(\n",
    "    \"Overview\", \"Computational Metascience\"\n",
    ")\n",
    "\n",
    "article_content_df['image_name'] = article_content_df['cover_image'].apply(lambda x: Path(x).name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_content_df = article_content_df[\n",
    "    (article_content_df[\"category\"] == \"News\")\n",
    "    | (\n",
    "        article_content_df[\"tags\"].apply(\n",
    "            lambda x: \"news\" in x if isinstance(x, list) else False\n",
    "        )\n",
    "    )\n",
    "].sort_values(by=[\"date\"], ascending=[False])\n",
    "\n",
    "research_content_df = article_content_df[\n",
    "    article_content_df[\"category\"] != \"News\"\n",
    "].sort_values(by=[\"category\", \"date\"], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_json_list = []\n",
    "for single_info_file_path in MEMBERS_DIR_PATH.glob(\"*/info.json\"):\n",
    "    with open(single_info_file_path, \"r\") as f_info:\n",
    "        member_data = json.load(f_info)\n",
    "    # if len(member_data.keys()) == 1:\n",
    "    #     info_json_path = (\n",
    "    #         KERZENDORF_GROUP_DATA / \"members\" / member_data[\"id\"] / \"info.json\"\n",
    "    #     )\n",
    "    #     member_images_dir = HOSTING_PATH / \"members\" / member_data[\"id\"] / \"media\"\n",
    "    #     with open(info_json_path, \"r\") as f_info_kl:\n",
    "    #         member_data_from_kl = json.load(f_info_kl)\n",
    "    #     member_images_dir_source = (\n",
    "    #         KERZENDORF_GROUP_DATA / \"members\" / member_data[\"id\"] / \"media\"\n",
    "    #     )\n",
    "\n",
    "    #     shutil.copytree(member_images_dir_source, member_images_dir, dirs_exist_ok=True)\n",
    "    #     info_json_list.append(member_data_from_kl)\n",
    "    # else:\n",
    "    info_json_list.append(member_data)\n",
    "info_json_df = pd.DataFrame(info_json_list)\n",
    "info_json_df.set_index(\"id\", inplace=True)\n",
    "info_json_df[\"full_name\"] = info_json_df.apply(\n",
    "    lambda row: (\n",
    "        row[\"nick_name\"] + \" \" + row[\"last_name\"]\n",
    "        if pd.notna(row[\"nick_name\"])\n",
    "        else row[\"first_name\"] + \" \" + row[\"last_name\"]\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "info_json_dict = info_json_df.to_dict(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = read_member_data_jsons(\"experiences.json\")[\n",
    "    [\n",
    "        \"role\",\n",
    "        \"start_date\",\n",
    "        \"end_date\",\n",
    "        \"institution\",\n",
    "        \"group\",\n",
    "    ]\n",
    "]\n",
    "edu_df = read_member_data_jsons(\"education.json\")[\n",
    "    [\"start_date\", \"end_date\", \"institution\", \"subject\", \"degree\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_df['end_date'] = pd.to_datetime(edu_df['end_date'], format='%Y-%m-%d')\n",
    "edu_df['start_date'] = pd.to_datetime(edu_df['start_date'], format='%Y-%m-%d')\n",
    "\n",
    "\n",
    "def most_recent_row(group):\n",
    "    return group[group[\"start_date\"] == group[\"start_date\"].max()]\n",
    "edu_df_most_recent = (\n",
    "    edu_df.groupby(\"id\").apply(most_recent_row).droplevel(0)\n",
    ")\n",
    "\n",
    "edu_df_most_recent['academic_role'] = \"\"\n",
    "for edu_mem_id, edu_mem_value in edu_df_most_recent.iterrows():\n",
    "    if edu_mem_value['institution'] == INSTITUTION_FILTER:\n",
    "        if edu_mem_value['degree'] == \"Bachelors\":\n",
    "            edu_df_most_recent.at[edu_mem_id, 'academic_role'] = \"Undergraduate Student\"\n",
    "        elif edu_mem_value['degree'] in [\"PhD\", \"Masters\"]:\n",
    "            edu_df_most_recent.at[edu_mem_id, 'academic_role'] = \"Graduate Student\"\n",
    "edu_df_most_recent_diff_suffix = edu_df_most_recent.add_suffix(\"_edu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_link_list = []\n",
    "for single_member_file_path in MEMBERS_DIR_PATH.rglob(\"social_links.json\"):\n",
    "    with open(single_member_file_path, \"r\") as fname:\n",
    "        member_social_link = json.load(fname)\n",
    "    info_json_file_path = single_member_file_path.parent.parent / \"info.json\"\n",
    "    with open(info_json_file_path, \"r\") as file_info:\n",
    "        member_info_data = json.load(file_info)\n",
    "    mem_id = member_info_data[\"id\"]\n",
    "    member_social_link[\"id\"] = mem_id\n",
    "    social_link_list.append(member_social_link)\n",
    "social_links_df = pd.DataFrame(social_link_list)\n",
    "social_links_df.set_index(\"id\", inplace=True)\n",
    "social_links_df.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_content = article_content_df.sort_values(\n",
    "    by=[\"category\", \"date\"], ascending=[True, False]\n",
    ")\n",
    "# Get the first row for each category using groupby and head\n",
    "recent_content = recent_content.groupby(\"category\").head(1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Page Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create a page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.337418487Z",
     "start_time": "2023-11-21T07:07:36.065742781Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_page(template, html, **kwargs):\n",
    "    \"\"\"\n",
    "    Create an HTML page using a Jinja2 template and save it to a specified path.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    template : str\n",
    "        The filename of the Jinja2 template to be used.\n",
    "    html : str\n",
    "        The filename of the HTML file to be generated.\n",
    "    **kwargs : dict\n",
    "        Additional keyword arguments to be passed to the Jinja2 template for rendering.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    page_template = environment.get_template(template)\n",
    "    template_level = html.count(\"/\")\n",
    "    page_html_path = HOSTING_PATH / html\n",
    "    page_html_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    page_content = page_template.render(TEMPLATE_LEVEL=template_level, **kwargs)\n",
    "    with open(page_html_path, mode=\"w\", encoding=\"utf-8\") as page:\n",
    "        page.write(page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing List Of JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.392640967Z",
     "start_time": "2023-11-21T07:07:36.099540795Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function Call\n",
    "general = loading_website_data(\"general\")\n",
    "homepage = loading_website_data(\"homepage\")\n",
    "contact = loading_website_data(\"contact\")\n",
    "research = loading_website_data(\"research_categories\")\n",
    "support = loading_website_data(\"support\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homepage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing selected columns for Homepage only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.460321141Z",
     "start_time": "2023-11-21T07:07:36.164866903Z"
    }
   },
   "outputs": [],
   "source": [
    "create_page(\n",
    "    \"homepage.html.j2\",\n",
    "    \"index.html\",\n",
    "    general=general,\n",
    "    homepage=homepage,\n",
    "    recent_content=recent_content.to_dict(orient=\"records\"),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current Members Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.460567962Z",
     "start_time": "2023-11-21T07:07:36.165051029Z"
    }
   },
   "outputs": [],
   "source": [
    "exp_df['end_date'] = pd.to_datetime(exp_df['end_date'], format='%Y-%m-%d')\n",
    "exp_df['start_date'] = pd.to_datetime(exp_df['start_date'], format='%Y-%m-%d')\n",
    "exp_df = exp_df.fillna(\"\")\n",
    "filtered_exp_df = exp_df[(exp_df[\"end_date\"].isna()) | (exp_df[\"end_date\"].dt.date >= datetime.now().date())]\n",
    "def most_recent_row(group):\n",
    "    sorted_group = group.sort_values(by=['start_date', 'end_date'], ascending=[False, True])\n",
    "    # Filter the sorted group by the condition that the group name is in GROUP_FILTER\n",
    "    relevant_group = sorted_group[sorted_group['group'].str.contains('|'.join(GROUP_FILTER))]\n",
    "    # Return the most recent relevant experience\n",
    "    return relevant_group.head(1)\n",
    "filtered_exp_df_most_recent = exp_df.groupby(\"id\").apply(most_recent_row).droplevel(0)\n",
    "exp_df_most_recent = exp_df.groupby(\"id\").apply(most_recent_row).droplevel(0)\n",
    "exp_df_most_recent_diff_suffix = exp_df_most_recent.add_suffix('_exp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_edu_exp_df = exp_df_most_recent_diff_suffix.merge(edu_df_most_recent_diff_suffix, on='id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_edu_exp_df['isCurrent'] = False\n",
    "merged_edu_exp_df['current_role'] = \"\"\n",
    "for merged_mem_id, merged_mem_value in merged_edu_exp_df.iterrows():\n",
    "    if merged_mem_value['institution_edu'] == INSTITUTION_FILTER:\n",
    "        if pd.isna(merged_mem_value['end_date_edu']) or merged_mem_value['end_date_edu'] >= datetime.now():\n",
    "            merged_mem_value['isCurrent'] = True\n",
    "            if pd.notna(merged_mem_value['end_date_exp']):\n",
    "                merged_mem_value['isCurrent'] = False\n",
    "            acad_role = merged_mem_value.get('academic_role_edu')\n",
    "            if acad_role:\n",
    "                merged_mem_value['current_role'] = merged_mem_value[\"academic_role_edu\"]\n",
    "        else:\n",
    "            merged_mem_value['isCurrent'] = False\n",
    "            acad_role = merged_mem_value.get('academic_role_edu')\n",
    "            if acad_role:\n",
    "                merged_mem_value['current_role'] = merged_mem_value[\"academic_role_edu\"]\n",
    "            else:\n",
    "                merged_mem_value['current_role'] = merged_mem_value[\"role_exp\"]\n",
    "    elif merged_mem_value['group_exp'] in GROUP_FILTER and (pd.isna(merged_mem_value['end_date_exp']) or merged_mem_value['end_date_exp'] >= datetime.now()):\n",
    "            merged_mem_value['isCurrent'] = True\n",
    "            merged_mem_value['current_role'] = merged_mem_value[\"role_exp\"]\n",
    "    else:\n",
    "        merged_mem_value['isCurrent'] = False\n",
    "        acad_role = merged_mem_value.get('academic_role_edu')\n",
    "        if acad_role:\n",
    "            merged_mem_value['current_role'] = merged_mem_value[\"academic_role_edu\"]\n",
    "        else:\n",
    "            merged_mem_value['current_role'] = merged_mem_value[\"role_exp\"]\n",
    "    merged_edu_exp_df.loc[merged_mem_id] = merged_mem_value\n",
    "merged_edu_exp_df['current_role'] = merged_edu_exp_df['current_role'].replace(ROLE_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_member_df = merged_edu_exp_df[merged_edu_exp_df['isCurrent'] == True][[\"current_role\"]]\n",
    "current_member_df_with_info = pd.merge(current_member_df, info_json_df, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "alumni_member_df = merged_edu_exp_df[merged_edu_exp_df['isCurrent'] == False][[\"current_role\"]]\n",
    "alumni_member_df_with_info = pd.merge(alumni_member_df, info_json_df, on='id', how='inner')[['current_role', 'full_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_df = read_member_data_jsons(\"projects.json\").sort_values(\n",
    "    by=[\"end_date\"], ascending=False\n",
    ")\n",
    "projects_df['end_date'] = pd.to_datetime(projects_df['end_date'], format='%Y-%m-%d')\n",
    "projects_df['start_date'] = pd.to_datetime(projects_df['start_date'], format='%Y-%m-%d')\n",
    "projects_df.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mem_key, mem_value in current_member_df.iterrows():\n",
    "    if mem_key in projects_df.index:\n",
    "        mem_projects = projects_df.loc[mem_key]\n",
    "        if not mem_projects.empty:\n",
    "            if isinstance(mem_projects, pd.Series):\n",
    "                current_project_title = mem_projects[\"project_title\"]\n",
    "            else:\n",
    "                current_project_title = mem_projects.iloc[0][\"project_title\"]\n",
    "    else:\n",
    "        current_project_title = \"\"\n",
    "    current_member_df_with_info.loc[mem_key, \"current_project_title\"] = current_project_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to sort the members on basis of their roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_role</th>\n",
       "      <th>full_name</th>\n",
       "      <th>image_path</th>\n",
       "      <th>cover_image_path</th>\n",
       "      <th>current_project_title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolfgang_kerzendorf</th>\n",
       "      <td>Professor</td>\n",
       "      <td>Wolfgang Kerzendorf</td>\n",
       "      <td>media/images/wolfgang.jpg</td>\n",
       "      <td>media/images/cover.jpg</td>\n",
       "      <td>Supernovae &amp; Computational Metaresearch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anirban_dutta</th>\n",
       "      <td>Postdoctoral Researcher</td>\n",
       "      <td>Anirban  Dutta</td>\n",
       "      <td>media/images/anirban_dutta.jpg</td>\n",
       "      <td>media/images/cover.jpg</td>\n",
       "      <td>Non-LTE modeling of supernova spectra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jing_lu</th>\n",
       "      <td>Postdoctoral Researcher</td>\n",
       "      <td>Jing Lu</td>\n",
       "      <td>media/images/jing.jpg</td>\n",
       "      <td>media/images/cover.jpg</td>\n",
       "      <td>Explore the hidden Helium in Type Ic Supernovae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vicente_amado</th>\n",
       "      <td>Graduate Student</td>\n",
       "      <td>Vicente  Amado Olivo</td>\n",
       "      <td>media/images/ESD_headshot.jpg</td>\n",
       "      <td>media/images/cover.jpg</td>\n",
       "      <td>Development Of A Global Registry For Peer Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>erin_visser</th>\n",
       "      <td>Undergraduate Student</td>\n",
       "      <td>Erin Visser</td>\n",
       "      <td>media/images/erin_visser_website_pic.jpg</td>\n",
       "      <td>media/images/cover.jpg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alexander_grunewald</th>\n",
       "      <td>Undergraduate Student</td>\n",
       "      <td>Alexander Grunewald</td>\n",
       "      <td>media/images/alexander.jpg</td>\n",
       "      <td>media/images/cover.jpg</td>\n",
       "      <td>Emulator Project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cecelia_powers</th>\n",
       "      <td>Undergraduate Student</td>\n",
       "      <td>Cecelia Powers</td>\n",
       "      <td>media/images/cecelia_powers_profilepic.jpeg</td>\n",
       "      <td>media/images/cover.jpg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bea_lu</th>\n",
       "      <td>Undergraduate Student</td>\n",
       "      <td>Bea Lu</td>\n",
       "      <td>media/images/bea_lu.jpg</td>\n",
       "      <td>media/images/cover.jpg</td>\n",
       "      <td>Natural Language Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ryan_groneck</th>\n",
       "      <td>Undergraduate Student</td>\n",
       "      <td>Ryan Groneck</td>\n",
       "      <td>media/images/Ryan_Groneck_Website_Picture.jpg</td>\n",
       "      <td>media/images/cover.jpg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logan_mcclellan</th>\n",
       "      <td>Undergraduate Student</td>\n",
       "      <td>Logan  McClellan</td>\n",
       "      <td>media/images/logan_mcclellan.jpg</td>\n",
       "      <td>media/images/cover.jpg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abhinav_ohri</th>\n",
       "      <td>Research Software Engineer</td>\n",
       "      <td>Abhinav Ohri</td>\n",
       "      <td>media/images/abhinav_ohri.jpg</td>\n",
       "      <td>media/images/cover.jpg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atharva_arya</th>\n",
       "      <td>Research Software Engineer</td>\n",
       "      <td>Atharva Arya</td>\n",
       "      <td>media/images/atharva.jpg</td>\n",
       "      <td>media/images/cover.jpg</td>\n",
       "      <td>Mitigating open science sustainability issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaladh_singhal</th>\n",
       "      <td>Visualization Consultant</td>\n",
       "      <td>Jaladh Singhal</td>\n",
       "      <td>media/images/jaladh.jpg</td>\n",
       "      <td>media/images/cover.jpg</td>\n",
       "      <td>Space Tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andrew_fullard</th>\n",
       "      <td>Researcher</td>\n",
       "      <td>Andrew Fullard</td>\n",
       "      <td>media/images/me.jpg</td>\n",
       "      <td>media/images/cover.jpg</td>\n",
       "      <td>Inferring explosion conditions from late-time ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   current_role             full_name  \\\n",
       "id                                                                      \n",
       "wolfgang_kerzendorf                   Professor   Wolfgang Kerzendorf   \n",
       "anirban_dutta           Postdoctoral Researcher        Anirban  Dutta   \n",
       "jing_lu                 Postdoctoral Researcher               Jing Lu   \n",
       "vicente_amado                  Graduate Student  Vicente  Amado Olivo   \n",
       "erin_visser               Undergraduate Student           Erin Visser   \n",
       "alexander_grunewald       Undergraduate Student   Alexander Grunewald   \n",
       "cecelia_powers            Undergraduate Student        Cecelia Powers   \n",
       "bea_lu                    Undergraduate Student                Bea Lu   \n",
       "ryan_groneck              Undergraduate Student          Ryan Groneck   \n",
       "logan_mcclellan           Undergraduate Student      Logan  McClellan   \n",
       "abhinav_ohri         Research Software Engineer          Abhinav Ohri   \n",
       "atharva_arya         Research Software Engineer          Atharva Arya   \n",
       "jaladh_singhal         Visualization Consultant        Jaladh Singhal   \n",
       "andrew_fullard                       Researcher        Andrew Fullard   \n",
       "\n",
       "                                                        image_path  \\\n",
       "id                                                                   \n",
       "wolfgang_kerzendorf                      media/images/wolfgang.jpg   \n",
       "anirban_dutta                       media/images/anirban_dutta.jpg   \n",
       "jing_lu                                      media/images/jing.jpg   \n",
       "vicente_amado                        media/images/ESD_headshot.jpg   \n",
       "erin_visser               media/images/erin_visser_website_pic.jpg   \n",
       "alexander_grunewald                     media/images/alexander.jpg   \n",
       "cecelia_powers         media/images/cecelia_powers_profilepic.jpeg   \n",
       "bea_lu                                     media/images/bea_lu.jpg   \n",
       "ryan_groneck         media/images/Ryan_Groneck_Website_Picture.jpg   \n",
       "logan_mcclellan                   media/images/logan_mcclellan.jpg   \n",
       "abhinav_ohri                         media/images/abhinav_ohri.jpg   \n",
       "atharva_arya                              media/images/atharva.jpg   \n",
       "jaladh_singhal                             media/images/jaladh.jpg   \n",
       "andrew_fullard                                 media/images/me.jpg   \n",
       "\n",
       "                           cover_image_path  \\\n",
       "id                                            \n",
       "wolfgang_kerzendorf  media/images/cover.jpg   \n",
       "anirban_dutta        media/images/cover.jpg   \n",
       "jing_lu              media/images/cover.jpg   \n",
       "vicente_amado        media/images/cover.jpg   \n",
       "erin_visser          media/images/cover.jpg   \n",
       "alexander_grunewald  media/images/cover.jpg   \n",
       "cecelia_powers       media/images/cover.jpg   \n",
       "bea_lu               media/images/cover.jpg   \n",
       "ryan_groneck         media/images/cover.jpg   \n",
       "logan_mcclellan      media/images/cover.jpg   \n",
       "abhinav_ohri         media/images/cover.jpg   \n",
       "atharva_arya         media/images/cover.jpg   \n",
       "jaladh_singhal       media/images/cover.jpg   \n",
       "andrew_fullard       media/images/cover.jpg   \n",
       "\n",
       "                                                 current_project_title  \n",
       "id                                                                      \n",
       "wolfgang_kerzendorf            Supernovae & Computational Metaresearch  \n",
       "anirban_dutta                    Non-LTE modeling of supernova spectra  \n",
       "jing_lu                Explore the hidden Helium in Type Ic Supernovae  \n",
       "vicente_amado        Development Of A Global Registry For Peer Revi...  \n",
       "erin_visser                                                             \n",
       "alexander_grunewald                                   Emulator Project  \n",
       "cecelia_powers                                                          \n",
       "bea_lu                                     Natural Language Processing  \n",
       "ryan_groneck                                                            \n",
       "logan_mcclellan                                                         \n",
       "abhinav_ohri                                                            \n",
       "atharva_arya             Mitigating open science sustainability issues  \n",
       "jaladh_singhal                                             Space Tools  \n",
       "andrew_fullard       Inferring explosion conditions from late-time ...  "
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(ROLE_HIERARCHY_PATH, \"r\") as file_name:  \n",
    "    role_hierarchy = json.load(file_name)\n",
    "current_member_df_with_info['rank'] = current_member_df_with_info['current_role'].map(role_hierarchy)\n",
    "\n",
    "current_member_df_with_info = current_member_df_with_info.sort_values(by='rank')\n",
    "current_member_df_with_info = current_member_df_with_info.drop(columns='rank')\n",
    "current_member_df_with_info[['current_role', 'full_name', 'image_path', 'cover_image_path','current_project_title']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current Members Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_page(\n",
    "    \"current_members.html.j2\",\n",
    "    \"current_members.html\",\n",
    "    general=general,\n",
    "    current_members=current_member_df_with_info,\n",
    "    socials=social_links_df.to_dict(\"index\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alumni Members Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_page(\n",
    "    \"alumni_members.html.j2\",\n",
    "    \"alumni_members.html\",\n",
    "    general=general,\n",
    "    alumni_members=alumni_member_df_with_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual People Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_df(df):\n",
    "    new_df = (df.fillna(\"\").groupby(\"id\")\n",
    "    .apply(lambda x: x.to_dict(orient=\"records\"))\n",
    "    .reset_index(name=\"info\")\n",
    "    .set_index(\"id\")\n",
    "    .to_dict(orient=\"index\"))\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_df = read_member_data_jsons(\"documents.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outreach_df = read_member_data_jsons(\"outreach.json\")\n",
    "if not outreach_df.empty:\n",
    "    outreach_grouped = group_df(outreach_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_df = read_member_data_jsons(\"awards.json\")\n",
    "awards_grouped = group_df(awards_df)\n",
    "\n",
    "exp_grouped = group_df(exp_df)\n",
    "edu_grouped = group_df(edu_df)\n",
    "projects_grouped = group_df(projects_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_json_df.fillna(\"\", inplace=True)\n",
    "for member_id, member_data in info_json_df.iterrows():\n",
    "    if member_id in current_member_df_with_info.index:\n",
    "        info_json_df.at[member_id, \"academic_role\"] = current_member_df_with_info.loc[\n",
    "            member_id, \"current_role\"\n",
    "        ]\n",
    "        info_json_df.at[member_id, \"current_project_title\"] = current_member_df_with_info.loc[\n",
    "            member_id, \"current_project_title\"\n",
    "        ]\n",
    "    elif member_id in alumni_member_df.index:\n",
    "        info_json_df.at[member_id, \"academic_role\"] = alumni_member_df.loc[\n",
    "            member_id, \"current_role\"\n",
    "        ]\n",
    "alumni_member_df.replace(\"nan\", np.nan, inplace=True)\n",
    "alumni_member_df.fillna(\"\", inplace=True)\n",
    "current_member_df_with_info.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for person_id, person_data in info_json_df.iterrows():\n",
    "    create_page(\n",
    "        \"individual_person.html.j2\",\n",
    "        f\"members/{person_id}/{person_id}.html\",\n",
    "        general=general,\n",
    "        member_id=person_id,\n",
    "        member_data=person_data,\n",
    "        socials=social_links_df.to_dict(\"index\"),\n",
    "        documents=document_df.to_dict(\"index\"),\n",
    "        education=edu_grouped,\n",
    "        experience=exp_grouped,\n",
    "        projects=projects_grouped,\n",
    "        awards=awards_grouped,\n",
    "        outreach=outreach_df,\n",
    "        section_headings=INDIVIDUAL_MEMBER_SECTION_MAP,\n",
    "        content=article_content_df.to_dict(\"index\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Contact Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.569018310Z",
     "start_time": "2023-11-21T07:07:36.457030906Z"
    }
   },
   "outputs": [],
   "source": [
    "create_page(\n",
    "    \"contact.html.j2\",\n",
    "    \"Contact.html\",\n",
    "    general=general,\n",
    "    contact=contact\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Support Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.588932886Z",
     "start_time": "2023-11-21T07:07:36.457249500Z"
    }
   },
   "outputs": [],
   "source": [
    "create_page(\n",
    "    \"support.html.j2\",\n",
    "    \"Support.html\",\n",
    "    general=general,\n",
    "    support=support\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Research Front Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For adding more columns in dataframe to render front pages and individual article pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.589247191Z",
     "start_time": "2023-11-21T07:07:36.501093779Z"
    }
   },
   "outputs": [],
   "source": [
    "create_page(\n",
    "    \"research.html.j2\",\n",
    "    \"Research.html\",\n",
    "    general=general,\n",
    "    content=research_content_df,\n",
    "    research=research,\n",
    "    current_members=info_json_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.589414282Z",
     "start_time": "2023-11-21T07:07:36.544920583Z"
    }
   },
   "outputs": [],
   "source": [
    "SUB_RESEARCH_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for category in article_content_df.loc[\n",
    "    article_content_df.category != \"News\", \"category\"\n",
    "].unique():\n",
    "    create_page(\n",
    "        \"sub_research_frontpage.html.j2\",\n",
    "        f\"sub_research/{page_link(category.lower())}.html\",\n",
    "        general=general,\n",
    "        research=research,\n",
    "        content=research_content_df,\n",
    "        category=category,\n",
    "        current_members=info_json_dict,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.589414282Z",
     "start_time": "2023-11-21T07:07:36.544920583Z"
    }
   },
   "source": [
    "Individual Research Page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:07:36.589414282Z",
     "start_time": "2023-11-21T07:07:36.544920583Z"
    }
   },
   "outputs": [],
   "source": [
    "for ind_research_keys, ind_research_values in research_content_df.iterrows():\n",
    "    destination_research_path = f\"sub_research/{page_link(ind_research_values.category.lower())}/{page_link(ind_research_values.article_id.lower())}.html\"\n",
    "    if ind_research_values['category'] == \"Software\":\n",
    "        destination_research_path = f\"sub_research/{page_link(ind_research_values.article_id.lower())}.html\"\n",
    "\n",
    "    folder_path = SUB_RESEARCH_PATH / page_link(ind_research_values.category.lower())\n",
    "    folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    create_page(\n",
    "        \"research_page_no_twitter.html.j2\",\n",
    "        destination_research_path,\n",
    "        general=general,\n",
    "        content=ind_research_values,\n",
    "        member_data=info_json_dict,\n",
    "        article_id=ind_research_values[\"article_id\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def urlize_content(content):\n",
    "    \"\"\"\n",
    "    Replaces IDs wrapped in [] with corresponding names from an existing DataFrame,\n",
    "    and wraps the names in anchor tags.\n",
    "\n",
    "    Args:\n",
    "        content (str): The text content containing IDs in square brackets.\n",
    "\n",
    "    Returns:\n",
    "        str: The updated content with IDs replaced by anchor tags.\n",
    "    \"\"\"\n",
    "\n",
    "    def replace_id(match):\n",
    "        id_to_fetch= match.group(1)\n",
    "        replace_string=\"\"\n",
    "        if id_to_fetch in info_json_df.index:\n",
    "            name = info_json_df.loc[id_to_fetch, 'full_name']\n",
    "            if id_to_fetch in current_member_df_with_info.index:\n",
    "                replace_string =f'<a href=\"../members/{id_to_fetch}/{id_to_fetch}.html\" target=\"_blank\">{name}</a>'\n",
    "            else:\n",
    "                replace_string = name\n",
    "        else:\n",
    "            replace_string = id_to_fetch.replace('_', ' ').title()\n",
    "\n",
    "        return replace_string\n",
    "\n",
    "    urlized_content = re.sub(r'\\[(\\w+)\\]', replace_id, content)\n",
    "\n",
    "    return urlized_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in news_content_df.iterrows():\n",
    "    content = row['content']\n",
    "    for content_key in content:\n",
    "        if \"para\" in content_key:\n",
    "            content[content_key] = urlize_content(content[content_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:10:29.508008736Z",
     "start_time": "2023-11-21T07:10:29.418263240Z"
    }
   },
   "outputs": [],
   "source": [
    "create_page(\n",
    "    \"news.html.j2\",\n",
    "    \"News.html\",\n",
    "    general=general,\n",
    "    content=news_content_df,\n",
    "    category=\"News\",\n",
    "    member_data=info_json_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual News Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_news_keys, ind_news_values in news_content_df.iterrows():\n",
    "    folder_path = HOSTING_PATH / \"news\" / page_link(ind_news_values.article_id.lower())\n",
    "    create_page(\n",
    "        \"news_page_no_twitter.html.j2\",\n",
    "        f\"news/{page_link(ind_news_values.article_id.lower())}.html\",\n",
    "        general=general,\n",
    "        content=ind_news_values,\n",
    "        member_data=info_json_dict,\n",
    "        category=\"News\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join Us Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OPPORTUNITIES_PATH, 'r') as f_opp:\n",
    "    OPPORTUNITIES = json.load(f_opp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_page(\n",
    "    \"join_us.html.j2\",\n",
    "    \"Join_Us.html\",\n",
    "    general=general,\n",
    "    opportunities=OPPORTUNITIES\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_research_data = []\n",
    "# for json_file in RESEARCH_CONTENT_SOURCE.rglob(\"info.json\"):\n",
    "#     sub_research = []\n",
    "#     relative_path = json_file.relative_to(RESEARCH_CONTENT_SOURCE.parent).with_suffix(\"\")\n",
    "#     for sub_dir in json_file.parent.iterdir():\n",
    "#         if sub_dir.is_dir():\n",
    "#             if sub_dir.name != \"media\":\n",
    "#                 sub_dir_name = sub_dir.name\n",
    "#                 sub_research.append(sub_dir_name)\n",
    "#             else:\n",
    "#                 dest_path = HOSTING_PATH / relative_path.parent\n",
    "#                 shutil.copytree(sub_dir, dest_path / \"media\", dirs_exist_ok=True)\n",
    "   \n",
    "#     # Parse the JSON file\n",
    "#     with open(json_file, \"r\") as f_research:\n",
    "#         data = json.load(f_research)\n",
    "#     if 'research_id' in data:\n",
    "#         data['sub_research'] = sub_research\n",
    "#         data['url'] = f\"{relative_path}.html\"\n",
    "#         all_research_data.append(data)\n",
    "# all_research_df = pd.DataFrame(all_research_data)\n",
    "# indexed_research_df = all_research_df.set_index('research_id')\n",
    "# # Fill all NaN values with empty strings in the DataFrame\n",
    "# indexed_research_df = indexed_research_df.fillna(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = {}\n",
    "\n",
    "# for index, article in article_content_df.iterrows():\n",
    "#     res_articles, news_articles = [], []\n",
    "#     if pd.notna(article[\"research_id\"]):\n",
    "#         res_id = article[\"research_id\"]\n",
    "#         article_id = article[\"article_id\"]\n",
    "#         if article['category'] == 'Research':\n",
    "#             res_articles.append((article_id, article['date']))\n",
    "#         if article['category'] == 'News':\n",
    "#             news_articles.append((article_id, article['date']))\n",
    "\n",
    "#         if res_id not in d:\n",
    "#             d[res_id] = {\"res_articles\": [], \"news_articles\": []}\n",
    "#         d[res_id][\"res_articles\"].extend(res_articles)\n",
    "#         d[res_id][\"news_articles\"].extend(news_articles)\n",
    "\n",
    "# def get_aggregated_articles(research_id, visited=None):\n",
    "#     if visited is None:\n",
    "#         visited = set()\n",
    "\n",
    "#     # Avoid processing the same research_id multiple times\n",
    "#     if research_id in visited:\n",
    "#         return {\"res_articles\": [], \"news_articles\": []}\n",
    "    \n",
    "#     visited.add(research_id)\n",
    "\n",
    "#     # Start with articles for the current research_id\n",
    "#     aggregated_articles = d.get(research_id, {\"res_articles\": [], \"news_articles\": []}).copy()\n",
    "\n",
    "#     # Get sub-research IDs from `indexed_research_df`\n",
    "#     sub_researches = indexed_research_df.loc[research_id, \"sub_research\"] if research_id in indexed_research_df.index else []\n",
    "#     if isinstance(sub_researches, list) and len(sub_researches) > 0:\n",
    "#         for sub_research in sub_researches:\n",
    "#             sub_articles = get_aggregated_articles(sub_research, visited)\n",
    "#             aggregated_articles[\"res_articles\"].extend(sub_articles[\"res_articles\"])\n",
    "#             aggregated_articles[\"news_articles\"].extend(sub_articles[\"news_articles\"])\n",
    "\n",
    "#     return aggregated_articles\n",
    "\n",
    "# f = {}\n",
    "# for research_index in indexed_research_df.index:\n",
    "#     f[research_index] = get_aggregated_articles(research_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sort_articles(articles):\n",
    "#     # Sort by date in descending order\n",
    "#     sorted_articles = sorted(articles, key=lambda x: x[1], reverse=True)\n",
    "#     # Extract only article IDs\n",
    "#     return [article[0] for article in sorted_articles]\n",
    "\n",
    "# # Update `f` with sorted articles\n",
    "# for research_index in f:\n",
    "#     f[research_index][\"res_articles\"] = sort_articles(f[research_index][\"res_articles\"])\n",
    "#     f[research_index][\"news_articles\"] = sort_articles(f[research_index][\"news_articles\"])\n",
    "\n",
    "# # Add sorted articles to `indexed_research_df`\n",
    "# indexed_research_df[\"res_articles\"] = indexed_research_df.index.map(\n",
    "#     lambda idx: f.get(idx, {}).get(\"res_articles\", [])\n",
    "# )\n",
    "# indexed_research_df[\"news_articles\"] = indexed_research_df.index.map(\n",
    "#     lambda idx: f.get(idx, {}).get(\"news_articles\", [])\n",
    "# )\n",
    "\n",
    "# # Display the updated DataFrame\n",
    "# indexed_research_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexed_article_df = article_content_df.set_index('article_id', inplace=False)\n",
    "# for index, research in indexed_research_df.iterrows():\n",
    "#     create_page(\n",
    "#         \"sub_research_frontpage.html.j2\",\n",
    "#         research['url'],\n",
    "#         general=general,\n",
    "#         data=research,\n",
    "#         current_research_id=index,\n",
    "#         indexed_research_df=indexed_research_df,\n",
    "#         indexed_article_df=indexed_article_df,\n",
    "#         member_data=info_json_dict\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gallery page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GALLERY_CONTENT_SOURCE = WEBSITE_DATA_PATH / \"content\" / \"gallery\"\n",
    "events = []\n",
    "\n",
    "for event_file in GALLERY_CONTENT_SOURCE.rglob(\"info.json\"):\n",
    "    with open(event_file, \"r\") as f_event:\n",
    "        event_data = json.load(f_event)\n",
    "    \n",
    "    if \"date\" in event_data:\n",
    "        event_data[\"date\"] = pd.to_datetime(event_data[\"date\"])\n",
    "    event_id = event_data.get(\"event_id\", \"unknown_event\")  # Default if event_id is missing\n",
    "    \n",
    "    # Define new destination path using event_id\n",
    "    dest_image_dir = HOSTING_PATH / \"website_files\" / \"images\" / \"gallery\" / event_id / \"media\" / \"images\"\n",
    "    \n",
    "    # Create destination directory if it doesn't exist\n",
    "    dest_image_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Copy images directory to the structured destination\n",
    "    source_image_dir = event_file.parent / \"media\" / \"images\"\n",
    "    if source_image_dir.exists():\n",
    "        shutil.copytree(source_image_dir, dest_image_dir, dirs_exist_ok=True)\n",
    "\n",
    "        # # Update image paths in event data to use website path\n",
    "        # for key in event_data:\n",
    "        #     if isinstance(event_data[key], str) and \"images\" in event_data[key]:\n",
    "        #         event_data[key] = str(Path(\"website_files\") / \"images\" / \"gallery\" / Path(event_data[key]).name)\n",
    "    for image in event_data.get(\"images\", []):\n",
    "        image_path = GALLERY_CONTENT_SOURCE / event_id / image[\"image_path\"]\n",
    "        with Image.open(image_path) as img:\n",
    "            width, height = img.size\n",
    "            new_width = int(width * 0.7)  # Reduce by 30%\n",
    "            new_height = int(height * 0.7)  # Reduce by 30%\n",
    "\n",
    "            image[\"scaled_width\"] = new_width\n",
    "            image[\"scaled_height\"] = new_height\n",
    "    events.append(event_data)\n",
    "\n",
    "create_page(\n",
    "    \"gallery.html.j2\",\n",
    "    \"Gallery.html\",\n",
    "    general=general,\n",
    "    member_data=info_json_dict,\n",
    "    events=events\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../../kerzendorf-lab.github.io/assets')"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_assets = GROUP_DATA_DIR.parent / \"groupwebsite_generator\" / \"assets\"\n",
    "shutil.copytree(source_assets, HOSTING_PATH / \"assets\", dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
