{
   "cells": [
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "### This notebook consist of code for creating the html files for the website each time data is updated."
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Set-up"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Importing classes"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 46,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:07:36.145701234Z",
               "start_time": "2023-11-21T07:07:35.993568325Z"
            }
         },
         "outputs": [],
         "source": [
            "import json\n",
            "import pandas as pd\n",
            "from jinja2 import Environment, FileSystemLoader\n",
            "from pathlib import Path\n",
            "import shutil\n",
            "from datetime import datetime, date"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Defining paths"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 47,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:07:36.276371007Z",
               "start_time": "2023-11-21T07:07:36.010519700Z"
            }
         },
         "outputs": [],
         "source": [
            "GROUP_DATA_DIR = Path(\"../../group-data\")\n",
            "TEMPLATE_DIR_PATH = GROUP_DATA_DIR.parent / \"groupwebsite_generator\" / \"templates\"\n",
            "WEBSITE_DATA_PATH = GROUP_DATA_DIR / \"website_data/\"\n",
            "HOSTING_PATH = GROUP_DATA_DIR.parent / \"kerzendorf-group.github.io\"\n",
            "ARTICLE_DIR_PATH = Path(\"../../research_news/articles\")\n",
            "ARTICLE_IMAGE_PATH = Path(\"../../research_news/images\")\n",
            "ARTICLE_IMAGE_DESTINATION_DIR = (HOSTING_PATH / \"website_files\" / \"images\" / \"article_content\")\n",
            "MEMBERS_DIR_PATH = GROUP_DATA_DIR / \"members/\"\n",
            "CONTENT_DIR_PATH = WEBSITE_DATA_PATH / \"content\"\n",
            "SUB_RESEARCH_PATH = HOSTING_PATH / \"sub_research\"\n",
            "\n",
            "ROLE_HIERARCHY_PATH = WEBSITE_DATA_PATH / \"role_hierarchy.json\""
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "Setting up jinja environment"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 48,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:07:36.311056453Z",
               "start_time": "2023-11-21T07:07:36.038221785Z"
            }
         },
         "outputs": [],
         "source": [
            "# Function to create proper HTML file names by replacing spaces with underscores\n",
            "def page_link(a):\n",
            "    \"\"\"Return the HTML file name after replacing blank spaces(\" \") with underscores(\"-\")\"\"\"\n",
            "    return a.replace(\" \", \"_\") if \" \" in a else a\n",
            "\n",
            "environment = Environment(\n",
            "    loader=FileSystemLoader(TEMPLATE_DIR_PATH), extensions=[\"jinja2.ext.loopcontrols\", \"jinja2.ext.do\"]\n",
            ")\n",
            "environment.globals[\"page_link\"] = page_link"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "# Data Processing Setup"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Data Processing Parameters"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 49,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:07:36.308005773Z",
               "start_time": "2023-11-21T07:07:36.024555660Z"
            }
         },
         "outputs": [],
         "source": [
            "# Needed columns for articles\n",
            "ARTICLE_METADATA_FIELDS = [\n",
            "    \"article_id\",\n",
            "    \"category\",\n",
            "    \"date\",\n",
            "    \"tags\",\n",
            "    \"title\",\n",
            "    \"cover_image\",\n",
            "    \"short_description\"\n",
            "]\n",
            "# Groups and institution used in filtering data\n",
            "GROUP_FILTER = [\"DTI\", \"TARDIS\", \"ICER\", \"kerzendorf\"]\n",
            "INSTITUTION_FILTER = \"Michigan State University\"\n",
            "\n",
            "# Map roles to standardized roles for consistency\n",
            "ROLE_MAP = {\n",
            "    \"Assistant Professor\": \"Professor\",\n",
            "    \"Professor\": \"Professor\",\n",
            "    \"Visualization Consultant\": \"Visualization Consultant\",\n",
            "    \"Research Consultant\": \"Research Consultant\",\n",
            "    \"Research Software Engineer\": \"Research Software Engineer\",\n",
            "    \"Professorial Assistant\": \"Undergraduate Student\",\n",
            "    \"Visiting Researcher\": \"Postdoctoral Researcher\",\n",
            "    \"Postdoctoral Researcher\": \"Postdoctoral Researcher\",\n",
            "}\n",
            "\n",
            "# Map degrees to standardized academic levels\n",
            "DEGREE_MAP = {\n",
            "    \"Masters\": \"Graduate Student\",\n",
            "    \"PhD\": \"Postdoctorate\",  #  if end_date is present\n",
            "    \"Bachelors\": \"Undergraduate Student\",\n",
            "}\n",
            "\n",
            "INDIVIDUAL_MEMBER_SECTION_MAP = {\n",
            "    \"education\": \"Education\",\n",
            "    \"experiences\": \"Experience\",\n",
            "    \"projects\": \"Projects\",\n",
            "    \"awards\": \"Awards & Recognition\",\n",
            "    \"outreach\": \"Outreach Programs\",\n",
            "}"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "# Functions for Data Handling"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 50,
         "metadata": {},
         "outputs": [],
         "source": [
            "def loading_website_data(file_to_load):\n",
            "    \"\"\"\n",
            "    Load data from JSON files specified in a list of file names.\n",
            "\n",
            "    Parameters:\n",
            "    ----------\n",
            "    json_data_list : list of str\n",
            "        A list of file names (without extension) to load as JSON.\n",
            "\n",
            "    Returns:\n",
            "    -------\n",
            "    dict\n",
            "        A dictionary where keys are file names and values are the corresponding JSON data.\n",
            "\n",
            "    Raises:\n",
            "    ------\n",
            "    FileNotFoundError:\n",
            "        If a specified file does not exist.\n",
            "    json.JSONDecodeError:\n",
            "        If there's an issue decoding the JSON content from a file.\n",
            "\n",
            "    \"\"\"\n",
            "    loaded_data = {}\n",
            "    file_matches = WEBSITE_DATA_PATH/ f\"{file_to_load}.json\"\n",
            "    if file_matches:\n",
            "        try:\n",
            "            with open(file_matches, \"r\") as json_file:\n",
            "                loaded_data = json.load(json_file)\n",
            "        except json.JSONDecodeError:\n",
            "            print(f\"Error decoding JSON in '{file_matches}'.\")\n",
            "    else:\n",
            "        print(f\"File '{file_to_load}.json' not found.\")\n",
            "\n",
            "    return loaded_data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 51,
         "metadata": {},
         "outputs": [],
         "source": [
            "def read_member_data_jsons(file_to_read):\n",
            "    member_data_list = []\n",
            "    member_data_df = pd.DataFrame([])\n",
            "    for single_info_file_path in MEMBERS_DIR.glob(\"*/info.json\"):\n",
            "        with open(single_info_file_path, \"r\") as f_info:\n",
            "            member_data = json.load(f_info)\n",
            "        member_unique_id = member_data[\"id\"]\n",
            "        file_to_read_path = single_info_file_path.parent / \"jsons\" / file_to_read\n",
            "\n",
            "        if file_to_read_path.exists():\n",
            "            with file_to_read_path.open(\"r\") as f_data:\n",
            "                member_other_data = json.load(f_data)\n",
            "            for entry in member_other_data:\n",
            "                entry[\"id\"] = member_unique_id\n",
            "            member_data_list.append(\n",
            "                pd.DataFrame(member_other_data)\n",
            "            )\n",
            "        else:\n",
            "            data_path_in_kl = KERZENDORF_GROUP_DATA / \"members\" / member_unique_id / \"jsons\" / file_to_read\n",
            "            if data_path_in_kl.exists():\n",
            "                with data_path_in_kl.open(\"r\") as data_file:\n",
            "                    member_other_data_kl = json.load(data_file)\n",
            "                for entry in member_other_data_kl:\n",
            "                    entry[\"id\"] = member_unique_id\n",
            "                member_data_list.append(\n",
            "                    pd.DataFrame(member_other_data_kl)\n",
            "                )\n",
            "\n",
            "    if member_data_list:\n",
            "        member_data_df = pd.concat(\n",
            "            member_data_list, ignore_index=True\n",
            "        )\n",
            "        member_data_df.set_index(\"id\", inplace=True)\n",
            "\n",
            "    return member_data_df"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 52,
         "metadata": {},
         "outputs": [],
         "source": [
            "def set_new_image_path(old_image_path):\n",
            "    image_source = ARTICLE_IMAGE_PATH / old_image_path.name\n",
            "    image_destination = ARTICLE_IMAGE_DESTINATION_DIR / old_image_path.name\n",
            "    website_files_index = image_destination.parts.index(\"website_files\")\n",
            "    new_image_path = Path(*image_destination.parts[website_files_index:])\n",
            "    shutil.copy2(image_source, image_destination)\n",
            "    return str(new_image_path)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "# DataFrame Creation and Processing"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Creating dataframes for articles which can be updated further "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 53,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:07:36.355136270Z",
               "start_time": "2023-11-21T07:07:36.080422459Z"
            }
         },
         "outputs": [],
         "source": [
            "# Reading all articles\n",
            "article_content_list = []\n",
            "today = date.today()\n",
            "for content_file_name in ARTICLE_DIR_PATH.iterdir():\n",
            "    with open(content_file_name, \"r\") as fcontent:\n",
            "        article_content = json.load(fcontent)\n",
            "    today_datetime = datetime.combine(today, datetime.min.time())\n",
            "    article_date = datetime.strptime(article_content[\"date\"], \"%m-%d-%Y\")\n",
            "    if \"kg\" in article_content[\"platforms\"] and article_date <= today_datetime:\n",
            "        image_path = Path(article_content[\"cover_image\"])\n",
            "        article_content[\"cover_image\"] = set_new_image_path(image_path)\n",
            "        for content_key, content_value in article_content[\"content\"].items():\n",
            "            if \"img\" in content_key:\n",
            "                new_content_value = set_new_image_path(Path(content_value))\n",
            "                article_content[\"content\"][content_key] = new_content_value\n",
            "        article_content_list.append(article_content)\n",
            "article_content_df = pd.DataFrame(article_content_list)\n",
            "\n",
            "article_content_df[\"date\"] = pd.to_datetime(\n",
            "    article_content_df[\"date\"], format=\"%m-%d-%Y\"\n",
            ")\n",
            "\n",
            "article_content_df[\"cover_image_height\"] = (\n",
            "    article_content_df[\"cover_image_height\"].fillna(\"330px\").replace(\"\", \"330px\")\n",
            ")\n",
            "article_content_df[\"cover_image_width\"] = (\n",
            "    article_content_df[\"cover_image_width\"].fillna(\"520px\").replace(\"\", \"520px\")\n",
            ")\n",
            "\n",
            "#THis line is only for kerzendorf lab and is not needed on dti\n",
            "article_content_df[\"category\"] = article_content_df[\"category\"].replace(\n",
            "    \"Overview\", \"Computational Metascience\"\n",
            ")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Extract the Latest Content for Each Category from a DataFrame"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 54,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:07:36.377192621Z",
               "start_time": "2023-11-21T07:07:36.092366454Z"
            },
            "jupyter": {
               "source_hidden": true
            }
         },
         "outputs": [],
         "source": [
            "def get_latest_content_df(input_data):\n",
            "    \"\"\"\n",
            "    Extract the latest content for each category from a DataFrame.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    input_data : pandas.DataFrame\n",
            "        The input DataFrame containing content information.\n",
            "\n",
            "    Returns\n",
            "    -------\n",
            "    pandas.DataFrame\n",
            "        A DataFrame containing the latest content for each category.\n",
            "\n",
            "    \"\"\"\n",
            "    # Sort the entire DataFrame by \"category\" and \"date\" in descending order\n",
            "    sorted_data = input_data.sort_values(\n",
            "        by=[\"category\", \"date\"], ascending=[True, False]\n",
            "    )\n",
            "\n",
            "    # Get the first row for each category using groupby and head\n",
            "    latest_data = sorted_data.groupby(\"category\").head(1).copy()\n",
            "    latest_data[\"date\"] = pd.to_datetime(\n",
            "        latest_data[\"date\"], format=\"%m-%d-%Y\"\n",
            "    )\n",
            "    latest_data = latest_data.sort_values(by=\"date\", ascending=False)\n",
            "\n",
            "    return latest_data"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "# Page Creation"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Function to create a page"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 55,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:07:36.337418487Z",
               "start_time": "2023-11-21T07:07:36.065742781Z"
            },
            "jupyter": {
               "source_hidden": true
            }
         },
         "outputs": [],
         "source": [
            "def create_page(template, html, **kwargs):\n",
            "    \"\"\"\n",
            "    Create an HTML page using a Jinja2 template and save it to a specified path.\n",
            "\n",
            "    Parameters:\n",
            "    ----------\n",
            "    template : str\n",
            "        The filename of the Jinja2 template to be used.\n",
            "    html : str\n",
            "        The filename of the HTML file to be generated.\n",
            "    **kwargs : dict\n",
            "        Additional keyword arguments to be passed to the Jinja2 template for rendering.\n",
            "\n",
            "    Returns:\n",
            "    -------\n",
            "    None\n",
            "\n",
            "    \"\"\"\n",
            "    page_template = environment.get_template(template)\n",
            "    template_level = html.count(\"/\")\n",
            "    page_html_path = HOSTING_PATH / html\n",
            "    page_html_path.parent.mkdir(parents=True, exist_ok=True)\n",
            "    page_content = page_template.render(TEMPLATE_LEVEL=template_level, **kwargs)\n",
            "    with open(page_html_path, mode=\"w\", encoding=\"utf-8\") as page:\n",
            "        page.write(page_content)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Processing List Of JSON files"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 56,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:07:36.392640967Z",
               "start_time": "2023-11-21T07:07:36.099540795Z"
            }
         },
         "outputs": [],
         "source": [
            "# Function Call\n",
            "general = loading_website_data(\"general\")\n",
            "homepage = loading_website_data(\"homepage\")\n",
            "contact = loading_website_data(\"contact\")\n",
            "research = loading_website_data(\"research_categories\")\n",
            "support = loading_website_data(\"support\")"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Homepage"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Storing selected columns for Homepage only"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 57,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:07:36.437636192Z",
               "start_time": "2023-11-21T07:07:36.114973108Z"
            }
         },
         "outputs": [],
         "source": [
            "content_df = article_content_df[ARTICLE_METADATA_FIELDS]\n",
            "latest_content_df = get_latest_content_df(content_df)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 58,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:07:36.460321141Z",
               "start_time": "2023-11-21T07:07:36.164866903Z"
            }
         },
         "outputs": [],
         "source": [
            "create_page(\n",
            "    \"homepage.html.j2\",\n",
            "    \"index.html\",\n",
            "    general=general,\n",
            "    homepage=homepage,\n",
            "    recent_content=latest_content_df.to_dict(orient=\"records\"),\n",
            ")"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# People Page"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Filtering based on group and institution"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 59,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:07:36.460567962Z",
               "start_time": "2023-11-21T07:07:36.165051029Z"
            }
         },
         "outputs": [],
         "source": [
            "def filter_edu_exp_data(df, valid_groups,valid_institution):\n",
            "    \"\"\"\n",
            "    Filter education and experience data based on specified criteria.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    df : pandas.DataFrame\n",
            "        The DataFrame containing education and experience data.\n",
            "    valid_groups : list\n",
            "        List of valid groups to include in the filtered data.\n",
            "    valid_institution : str\n",
            "        The valid institution to include in the filtered data.\n",
            "\n",
            "    Returns\n",
            "    -------\n",
            "    pandas.DataFrame\n",
            "        A filtered DataFrame containing only the rows that meet the specified criteria.\n",
            "    \"\"\"\n",
            "    group_mask = False\n",
            "    institution_mask = False\n",
            "\n",
            "    # Check if 'group' column exists and update mask accordingly\n",
            "    if \"group\" in df.columns:\n",
            "        group_mask = df[\"group\"].isin(valid_groups)\n",
            "\n",
            "    # Check if 'institution' column exists and update mask accordingly\n",
            "    if \"institution\" in df.columns:\n",
            "        institution_mask = df[\"institution\"] == valid_institution\n",
            "\n",
            "    final_mask = group_mask | institution_mask\n",
            "    return df[final_mask]"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Function to load education data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 60,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:07:36.460643612Z",
               "start_time": "2023-11-21T07:07:36.209021018Z"
            }
         },
         "outputs": [],
         "source": [
            "def load_education_experience_data(directory):\n",
            "    \"\"\"\n",
            "    Load education and experience data from JSON files, filter based on criteria, and perform preprocessing.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    directory : str or pathlib.Path\n",
            "        The directory path containing \"experiences.json\" and \"education.json\" files.\n",
            "\n",
            "    Returns\n",
            "    -------\n",
            "    pandas.DataFrame\n",
            "        A DataFrame containing filtered and preprocessed education and experience data.\n",
            "    \"\"\"\n",
            "    filtered_records = []\n",
            "    file_names = [\"experiences.json\", \"education.json\"]\n",
            "    for file_name in file_names:\n",
            "        file_path = directory / file_name\n",
            "        if file_path.exists():\n",
            "            # Reading JSON data using the json module\n",
            "            with open(file_path, \"r\") as file:\n",
            "                data = json.load(file)\n",
            "            \n",
            "            records = pd.DataFrame(data)\n",
            "\n",
            "            # filtering based on group and institution\n",
            "            valid_records = filter_edu_exp_data(records, GROUP_FILTER, INSTITUTION_FILTER)\n",
            "\n",
            "            filtered_records.append(valid_records)\n",
            "        else:\n",
            "            print(f\"{file_path} does not exist\")\n",
            "\n",
            "    if filtered_records:\n",
            "        combined_edu_exp_records = pd.concat(filtered_records, ignore_index=True)\n",
            "    else:\n",
            "        combined_edu_exp_records = pd.DataFrame()\n",
            "\n",
            "    # if start_date column exists, fill with NaN if it doesn't\n",
            "    if \"start_date\" not in combined_edu_exp_records:\n",
            "        combined_edu_exp_records[\"start_date\"] = pd.NaT\n",
            "\n",
            "    # Convert start_date to datetime format\n",
            "    combined_edu_exp_records[\"start_date\"] = pd.to_datetime(combined_edu_exp_records[\"start_date\"], errors=\"coerce\")\n",
            "\n",
            "    # Sort the DataFrame based on start_date\n",
            "    combined_edu_exp_records = combined_edu_exp_records.sort_values(by=\"start_date\", ascending=False)\n",
            "    return combined_edu_exp_records"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Function load social links directly"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 61,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:07:36.460739282Z",
               "start_time": "2023-11-21T07:07:36.209176046Z"
            }
         },
         "outputs": [],
         "source": [
            "def load_social_links(social_dir):\n",
            "    \"\"\"\n",
            "    Load social links from a JSON file.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    social_dir : str or pathlib.Path\n",
            "        The directory path containing the \"social_links.json\" file.\n",
            "\n",
            "    Returns\n",
            "    -------\n",
            "    dict or None\n",
            "        A dictionary containing social links or None if the file doesn't exist.\n",
            "    \"\"\"\n",
            "    social_links = None\n",
            "    social_links_file_path = social_dir / \"social_links.json\"\n",
            "    if social_links_file_path.exists():\n",
            "        with open(social_links_file_path, \"r\") as f:\n",
            "            social_links = json.load(f)\n",
            "    return social_links"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Function to load topmost project title"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 62,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:07:36.460804351Z",
               "start_time": "2023-11-21T07:07:36.209270143Z"
            }
         },
         "outputs": [],
         "source": [
            "def load_latest_project_title(project_dir):\n",
            "    \"\"\"\n",
            "    Load the title of the topmost project from a JSON file.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    project_dir : str or pathlib.Path\n",
            "        The directory path containing the \"projects.json\" file.\n",
            "\n",
            "    Returns\n",
            "    -------\n",
            "    str or None\n",
            "        The title of the topmost project or None if the file doesn't exist or is empty.\n",
            "    \"\"\"\n",
            "    projects_file_path = project_dir / \"projects.json\"\n",
            "    topmost_project_title = None\n",
            "    if projects_file_path.exists():\n",
            "        projects_df = pd.read_json(projects_file_path)\n",
            "        if not projects_df.empty:\n",
            "            # Fetching the project title from the first row of the DataFrame\n",
            "            topmost_project_title = projects_df.iloc[0].get(\"project_title\")\n",
            "    return topmost_project_title"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Funtion to parse member data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 63,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:07:36.460863639Z",
               "start_time": "2023-11-21T07:07:36.209362246Z"
            }
         },
         "outputs": [],
         "source": [
            "def parse_member_data(member_dir):\n",
            "    \"\"\"\n",
            "    Parse member-related data from JSON files in the specified directory.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    member_dir : str or pathlib.Path\n",
            "        The directory path containing member-related JSON files.\n",
            "\n",
            "    Returns\n",
            "    -------\n",
            "    tuple\n",
            "        A tuple containing education and experience DataFrame, social links dictionary,\n",
            "        and the title of the current project.\n",
            "    \"\"\"\n",
            "    member_json_dir = member_dir / \"jsons\"\n",
            "    education_experience_df = load_education_experience_data(member_json_dir)\n",
            "    current_project_title = load_latest_project_title(member_json_dir)\n",
            "    social_links = load_social_links(member_json_dir)\n",
            "\n",
            "    return education_experience_df, social_links, current_project_title"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Function to extract academic roles from education and experience data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 64,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:07:36.460921063Z",
               "start_time": "2023-11-21T07:07:36.209452896Z"
            }
         },
         "outputs": [],
         "source": [
            "def extract_member_academic_role(education_experience_df):\n",
            "    \"\"\"\n",
            "    Extract the current academic role of a member based on education and experience data.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    education_experience_df : pandas.DataFrame\n",
            "        DataFrame containing education and experience data.\n",
            "\n",
            "    Returns\n",
            "    -------\n",
            "    Tuple[str, bool]\n",
            "        A tuple containing:\n",
            "        - str: The current academic role of the member.\n",
            "        - bool: True if the member is currently active, False otherwise.\n",
            "    \"\"\"\n",
            "\n",
            "    # Check if these columns exist in dataframe\n",
            "    for column in [\"end_date\", \"group\", \"institution\"]:\n",
            "        if column not in education_experience_df.columns:\n",
            "            education_experience_df[column] = None\n",
            "\n",
            "    current_academic_role = None\n",
            "\n",
            "    for _, row in education_experience_df.iterrows():\n",
            "        role = row.get(\"role\", None)\n",
            "        degree = row.get(\"degree\", None)\n",
            "        member_institution = row.get('institution', None)\n",
            "        member_group = row.get('group', None)\n",
            "        end_date = row.get(\"end_date\", None)\n",
            "\n",
            "        if not current_academic_role:\n",
            "            current_academic_role = ROLE_MAP.get(role, \"\")\n",
            "            if degree == \"PhD\" or degree == \"Masters\":\n",
            "                if pd.isna(end_date) or (end_date and pd.to_datetime(end_date).date() >= datetime.now().date()):\n",
            "                    current_academic_role = \"Graduate Student\"\n",
            "            elif degree == \"Bachelors\":\n",
            "                if pd.isna(end_date) or (end_date and pd.to_datetime(end_date).date() >= datetime.now().date()):\n",
            "                    if member_institution == INSTITUTION_FILTER:\n",
            "                        if member_group in GROUP_FILTER:\n",
            "                            current_academic_role = \"Undergraduate Student\"\n",
            "                        else:\n",
            "                            current_academic_role = DEGREE_MAP[degree]\n",
            "                    else:\n",
            "                        current_academic_role = DEGREE_MAP[degree]\n",
            "            elif not current_academic_role and degree in DEGREE_MAP:\n",
            "                current_academic_role = DEGREE_MAP[degree]\n",
            "\n",
            "    # Check for end dates outside the loop\n",
            "    has_end_date = all(\n",
            "        not pd.isna(date) and (pd.to_datetime(date).date() < datetime.now().date())\n",
            "        for date in education_experience_df[\"end_date\"]\n",
            "    )\n",
            "    is_current_member = not has_end_date\n",
            "\n",
            "    return current_academic_role, is_current_member"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Function to sort the members on basis of their roles"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 65,
         "metadata": {
            "jupyter": {
               "source_hidden": true
            }
         },
         "outputs": [],
         "source": [
            "def custom_role_sort(roles):\n",
            "    \"\"\"\n",
            "    Sorts a list of roles based on academic role hierarchy and then by name.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    roles : list[dict]\n",
            "        List of dictionaries representing roles. Each dictionary should contain at least the keys 'academic_role' and 'name'.\n",
            "\n",
            "    Returns\n",
            "    -------\n",
            "    list[dict]\n",
            "        A sorted list of roles based on the academic role hierarchy and, in case of ties, sorted by name in ascending order.\n",
            "    \"\"\"\n",
            "    with open(ROLE_HIERARCHY_PATH, \"r\") as file_name:  \n",
            "        role_hierarchy = json.load(file_name)\n",
            "    sorted_roles = sorted(roles, key=lambda x: (role_hierarchy.get(x['academic_role'], float('inf')), x['name']))\n",
            "    return sorted_roles"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Function to store data for current and alumni members"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 66,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:07:36.460978768Z",
               "start_time": "2023-11-21T07:07:36.209625649Z"
            },
            "scrolled": true
         },
         "outputs": [],
         "source": [
            "def fetch_member_data():\n",
            "    \"\"\"\n",
            "    Fetch and process member data from directories in the specified members' directory.\n",
            "\n",
            "    Returns\n",
            "    -------\n",
            "    Tuple[list, list]\n",
            "        A tuple containing two lists:\n",
            "        1. List of dictionaries representing current members' data.\n",
            "        2. List of dictionaries representing alumni membersw' data.\n",
            "\n",
            "    \"\"\"\n",
            "    current_people_page_list = []\n",
            "    alumni_people_page_list = []\n",
            "    # Looping through member directories to fetch and process member data\n",
            "    for member_dir in MEMBERS_DIR_PATH.glob(\"*\"):\n",
            "        if \"template\" in str(member_dir):\n",
            "            continue\n",
            "        if not (member_info_fname := member_dir / \"info.json\").exists():\n",
            "            continue\n",
            "        with open(member_info_fname, \"r\") as file_name:\n",
            "            member_info = json.load(file_name)\n",
            "        (\n",
            "            education_experience_df,\n",
            "            social_links,\n",
            "            current_project_title,\n",
            "        ) = parse_member_data(member_dir)\n",
            "        current_academic_role, is_current_member = extract_member_academic_role(\n",
            "            education_experience_df\n",
            "        )\n",
            "        first_name = member_info[\"first_name\"]\n",
            "        last_name = member_info[\"last_name\"]\n",
            "        nick_name = member_info.get(\"nick_name\")\n",
            "        member_id = member_info[\"id\"]\n",
            "        image_path = member_info[\"image_path\"]\n",
            "        cover_image_path = member_info[\"cover_image_path\"]\n",
            "\n",
            "        name = f\"{nick_name if nick_name else first_name} {last_name}\"\n",
            "        member_data = {\n",
            "            \"name\": name,\n",
            "            \"academic_role\": current_academic_role,\n",
            "            \"id\": member_id,\n",
            "            \"current_project_title\": current_project_title,\n",
            "            \"image_path\": image_path,\n",
            "            \"cover_image_path\": cover_image_path,\n",
            "        }\n",
            "\n",
            "        if social_links is not None:\n",
            "            member_data[\"social_links\"] = social_links\n",
            "            \n",
            "        if is_current_member:\n",
            "            current_people_page_list.append(member_data)\n",
            "        else:\n",
            "            alumni_people_page_list.append(member_data)\n",
            "\n",
            "    # Sort current members by role\n",
            "    current_people_page_list = custom_role_sort(current_people_page_list)\n",
            "    \n",
            "    # Sort alumni members by role\n",
            "    alumni_people_page_list = custom_role_sort(alumni_people_page_list)\n",
            "    return current_people_page_list, alumni_people_page_list"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 67,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:07:36.566682059Z",
               "start_time": "2023-11-21T07:07:36.209725227Z"
            }
         },
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "../../group-data/members/vicente_amado/jsons/experiences.json does not exist\n",
                  "../../group-data/members/sona_chitchyan/jsons/experiences.json does not exist\n",
                  "../../group-data/members/jack_o_brien/jsons/experiences.json does not exist\n",
                  "../../group-data/members/yuki_matsumura/jsons/experiences.json does not exist\n"
               ]
            }
         ],
         "source": [
            "current_people_page_list, alumni_people_page_list = fetch_member_data()\n",
            "all_people_page_list = current_people_page_list + alumni_people_page_list\n",
            "all_people_data = {person[\"id\"]: person for person in all_people_page_list}"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Current Members Page"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 68,
         "metadata": {},
         "outputs": [],
         "source": [
            "create_page(\n",
            "    \"current_members.html.j2\",\n",
            "    \"current_members.html\",\n",
            "    general=general,\n",
            "    current_members=current_people_page_list,\n",
            ")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Alumni Members Page"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 69,
         "metadata": {},
         "outputs": [],
         "source": [
            "create_page(\n",
            "    \"alumni_members.html.j2\",\n",
            "    \"alumni_members.html\",\n",
            "    general=general,\n",
            "    alumni_members=alumni_people_page_list,\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 70,
         "metadata": {},
         "outputs": [],
         "source": [
            "def load_individual_member_data(member_id):\n",
            "    \"\"\"\n",
            "    Load data for an individual member based on their unique ID.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    member_id : str\n",
            "        Unique identifier for the member.\n",
            "\n",
            "    Returns\n",
            "    -------\n",
            "    tuple\n",
            "        A tuple containing:\n",
            "        - dict: Basic information about the member loaded from 'info.json'.\n",
            "        - dict: Dictionary containing various categories of member data loaded from respective JSON files.\n",
            "            The keys correspond to categories mapped in INDIVIDUAL_MEMBER_SECTION_MAP,\n",
            "            and values are dictionaries containing data for each category.\n",
            "    \"\"\"\n",
            "    member_dir = MEMBERS_DIR_PATH / member_id\n",
            "    member_jsons_dir = member_dir / \"jsons\"\n",
            "    member_info_dir = member_dir / \"info.json\"\n",
            "\n",
            "    with open(member_info_dir, \"r\") as file_name:\n",
            "        basic_info = json.load(file_name)\n",
            "\n",
            "    member_all_data = {}\n",
            "    for category in INDIVIDUAL_MEMBER_SECTION_MAP:\n",
            "        file_path = member_jsons_dir / f\"{category}.json\"\n",
            "        if file_path.exists():\n",
            "            with open(file_path, \"r\") as file_name:\n",
            "                member_all_data[category] = json.load(file_name)\n",
            "    \n",
            "    return basic_info, member_all_data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 71,
         "metadata": {},
         "outputs": [],
         "source": [
            "columns = [\"people_involved_ids\", \"category\", \"date\", \"title\", \"article_id\"]\n",
            "content_df = article_content_df[columns]\n",
            "\n",
            "for person_id, person_data in all_people_data.items():\n",
            "    basic_info, member_all_data = load_individual_member_data(person_id)\n",
            "    create_page(\n",
            "        \"individual_person.html.j2\",\n",
            "        f\"members/{person_id}/{person_id}.html\",\n",
            "        general=general,\n",
            "        member_id=person_id,\n",
            "        member_data=person_data,\n",
            "        basic_info=basic_info,\n",
            "        category_data=member_all_data,\n",
            "        section_headings=INDIVIDUAL_MEMBER_SECTION_MAP,\n",
            "        content=content_df.to_dict(orient='records')\n",
            "    )"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "# Contact Page"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 72,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:07:36.569018310Z",
               "start_time": "2023-11-21T07:07:36.457030906Z"
            }
         },
         "outputs": [],
         "source": [
            "create_page(\n",
            "    \"contact.html.j2\",\n",
            "    \"Contact.html\",\n",
            "    general=general,\n",
            "    contact=contact\n",
            ")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "# Support Page"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 73,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:07:36.588932886Z",
               "start_time": "2023-11-21T07:07:36.457249500Z"
            }
         },
         "outputs": [],
         "source": [
            "create_page(\n",
            "    \"support.html.j2\",\n",
            "    \"Support.html\",\n",
            "    general=general,\n",
            "    support=support\n",
            ")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "# Research Front Page"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "For adding more columns in dataframe to render front pages and individual article pages"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 74,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:07:36.589164156Z",
               "start_time": "2023-11-21T07:07:36.500941056Z"
            }
         },
         "outputs": [],
         "source": [
            "columns_extended = ARTICLE_METADATA_FIELDS + [\"author_id\"]\n",
            "content_df = article_content_df[columns_extended]\n",
            "research_content_df = content_df[content_df[\"category\"] != \"News\"].sort_values(\n",
            "    by=[\"category\", \"date\"], ascending=[True, False]\n",
            ")\n",
            "latest_content_df = get_latest_content_df(content_df)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 75,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:07:36.589247191Z",
               "start_time": "2023-11-21T07:07:36.501093779Z"
            }
         },
         "outputs": [],
         "source": [
            "create_page(\n",
            "    \"research.html.j2\",\n",
            "    \"Research.html\",\n",
            "    general=general,\n",
            "    content=research_content_df,\n",
            "    research=research,\n",
            "    current_members=current_people_page_list,\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 76,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:07:36.589414282Z",
               "start_time": "2023-11-21T07:07:36.544920583Z"
            }
         },
         "outputs": [],
         "source": [
            "folder_path = Path(HOSTING_PATH) / \"sub_research\"\n",
            "folder_path.mkdir(parents=True, exist_ok=True)\n",
            "\n",
            "for category in content_df.loc[content_df.category != \"News\", \"category\"].unique():\n",
            "    create_page(\n",
            "        \"sub_research_frontpage.html.j2\",\n",
            "        f\"sub_research/{page_link(category.lower())}.html\",\n",
            "        general=general,\n",
            "        research=research,\n",
            "        content=research_content_df,\n",
            "        category=category,\n",
            "        current_members=current_people_page_list\n",
            "    )"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:07:36.589414282Z",
               "start_time": "2023-11-21T07:07:36.544920583Z"
            }
         },
         "source": [
            "Individual Research Page\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 77,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:07:36.589414282Z",
               "start_time": "2023-11-21T07:07:36.544920583Z"
            }
         },
         "outputs": [],
         "source": [
            "columns_extended = ARTICLE_METADATA_FIELDS + [\"author_id\", \"people_involved_ids\", \"links\", \"content\", \"long_description\"]\n",
            "content_df = article_content_df[columns_extended]\n",
            "ind_research_content_df = content_df[content_df[\"category\"] != \"News\"].sort_values(\n",
            "    by=[\"category\", \"date\"], ascending=[True, False]\n",
            ")\n",
            "\n",
            "\n",
            "for ind_research_keys, ind_research_values in ind_research_content_df.iterrows():\n",
            "    \n",
            "    folder_path = Path(HOSTING_PATH) / \"sub_research\" / page_link(ind_research_values.category.lower())\n",
            "    folder_path.mkdir(parents=True, exist_ok=True)\n",
            "    create_page(\n",
            "        \"research_page_no_twitter.html.j2\",\n",
            "        f\"sub_research/{page_link(ind_research_values.category.lower())}/{page_link(ind_research_values.article_id.lower())}.html\",\n",
            "        general=general,\n",
            "        content=ind_research_values,\n",
            "        member_data=all_people_data,\n",
            "        article_id=ind_research_values['article_id']\n",
            "    )"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# News Page"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 78,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-11-21T07:10:29.508008736Z",
               "start_time": "2023-11-21T07:10:29.418263240Z"
            }
         },
         "outputs": [],
         "source": [
            "columns_extended = ARTICLE_METADATA_FIELDS + [\"author_id\", \"people_involved_ids\", \"content\", \"long_description\"]\n",
            "content_df = article_content_df[columns_extended]\n",
            "\n",
            "news_content_df = content_df[\n",
            "    (content_df[\"category\"] == \"News\") | (content_df[\"tags\"].apply(lambda x: \"news\" in x if isinstance(x, list) else False))\n",
            "].sort_values(by=[\"date\"], ascending=[False])\n",
            "\n",
            "create_page(\n",
            "    \"news.html.j2\",\n",
            "    \"News.html\",\n",
            "    general=general,\n",
            "    research=research,\n",
            "    content=news_content_df,\n",
            "    member_data=all_people_data,\n",
            "    category=\"News\"\n",
            ")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Individual News Page"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 79,
         "metadata": {},
         "outputs": [],
         "source": [
            "for ind_news_keys, ind_news_values in news_content_df.iterrows():\n",
            "    folder_path = Path(HOSTING_PATH) / \"news\" / page_link(ind_news_values.article_id.lower())\n",
            "    create_page(\n",
            "        \"news_page_no_twitter.html.j2\",\n",
            "        f\"news/{page_link(ind_news_values.article_id.lower())}.html\",\n",
            "        general=general,\n",
            "        content=ind_news_values,\n",
            "        member_data=all_people_data,\n",
            "        category=\"News\"\n",
            "    )"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3 (ipykernel)",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.14"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 4
}
